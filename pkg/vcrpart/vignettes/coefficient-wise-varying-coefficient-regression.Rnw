%\VignetteIndexEntry{Coefficient-Wise Tree-Based Varying Coefficient Regression with vcrpart}

\documentclass[article,shortnames,nojss]{jss}

\author{Reto B\"urgin \\ NCCR LIVES, Switzerland \And Gilbert Ritschard
  \\ NCCR LIVES, Switzerland}
\title{Coefficient-Wise Tree-Based Varying Coefficient Regression with
  \pkg{vcrpart}}

\Plainauthor{Reto B\"urgin, Gilbert Ritschard}
\Plaintitle{Coefficient-wise tree-based varying coefficient regression
  with vcrpart}

\Abstract{
The tree-based TVCM algorithm and its implementation in the
\proglang{R} package \pkg{vcrpart} is introduced for generalized
linear models. The purpose of TVCM is to learn whether and how the
coefficients of a regression model vary by moderating variables. A
separate partition is built for each potentially varying coefficient,
allowing the user to specify coefficient-specific sets of potential
moderators, and allowing the algorithm to select moderators
individually by coefficient. In addition to describing the algorithm,
the TVCM is evaluated using a benchmark comparison and a simulation
study and the \proglang{R} commands are demonstrated by means of
empirical applications.
}

\Keywords{regression trees, varying coefficient models,
  generalized linear models, statistical learning, \proglang{R}
  package, CART}
\Plainkeywords{regression trees, varying coefficient models,
  statistical learning, machine learning, R package, CART}

%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

\Address{
  Reto B\"urgin \\
  Swiss National Center in Competence in Research LIVES \\
  S\"udbahnhofstrasse 2 \\
  CH-3007 Bern, Switzerland \\
  E-mail: \email{rbuergin@gmx.ch}
  \par\bigskip
  Gilbert Ritschard\\
  Swiss National Center in Competence in Research LIVES \\
  IDESO, Centre Acacias 4 \\
  Route des Acacias 54 \\
  CH-1227 Carouge, Switzerland \\
  E-mail: \email{Gilbert.Ritschard@unige.ch}
}

\usepackage[utf8x]{inputenc}
%\usepackage{Sweave.sty}
% \usepackage{Sweave}
% \SweaveOpts{eps=TRUE}
%\SweaveOpts{encoding="UTF8"}
\SweaveOpts{prefix.string = Figures/jss2564}

\DefineVerbatimEnvironment{Sinput}{Verbatim}{
  fontsize=\normalsize}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{
  fontsize=\small}
\DefineVerbatimEnvironment{Scode}{Verbatim}{}

\usepackage{verbatim} %%for the comment environment
\usepackage[official]{eurosym}
\usepackage{amssymb}
\usepackage{amsmath,amsthm,amsfonts}
\usepackage[ruled,vlined,noend]{algorithm2e}
% \usepackage{booktabs}
\usepackage[svgnames]{xcolor}
\usepackage{natbib}
\newcommand{\stimes}{{\times}}

\usepackage{xr}

\begin{document}
\SweaveOpts{concordance=TRUE}

\raisebox{13.5cm}[0cm][0cm]{\parbox{\linewidth}{\small\normalfont This vignette is distributed with the \proglang{R} package \pkg{vcrpart}. Please cite as:\\[.5ex]
B\"{u}rgin, R. and G. Ritschard (2017). ``Coefficient-Wise Tree-Based Varying Coefficient Regression with \pkg{vcrpart}.'' \textit{Journal of Statistical Software}, \textbf{80}(6), 1--33. DOI \href{http://dx.doi.org/10.18637/jss.v080.i06}{10.18637/jss.v080.i06}}}


\section{Introduction}
\label{vcrpart-sec:intro}

<<label = header, echo = FALSE>>=

## Date:         2016-07-25
## Authors:      Reto Buergin and Gilbert Ritschard
## Institution:  Swiss National Centre of Competence in
##               Research LIVES (http://www.lives-nccr.ch/)
##
## R-codes for the article "Coefficient-wise
## tree-based varying coefficient regression with
## R-package 'vcrpart'". The code requires vcrpart (>= 0.4-1),
## mlbench (>= 2.1-1) and Ecdat (>= 0.2-9).
##
## Notes:
## Chunks with '(eval = FALSE)' in the header or
## with if / else conditions on 'run' objects are
## commented out because they are computationally
## burdensome. Instead, the pre-run results
## stored in supplementary files are used, see the
## commands
##
## load(file = "RData/vcrpart-applications.RData")
## load(file = "RData/vcrpart-bench.RData")
## load(file = "RData/vcrpart-simulations.RData")
##
## Depending where you have stored the RData files,
## you should modify these commands correspondingly.
##
## The comparison study of Section 4.1 or the the simulation
## study of section 4.2 can be processed by setting
## 'run <- TRUE' in the corresponding chunks.
##
## We cannot guarantee that the functions work with future
## versions of R and the indicated packages.
##
## Copyright R. Buergin and G. Ritschard, 2016
## distributed under license Creative Commons BY-NC-SA
## http://creativecommons.org/licenses/by-nc-sa/3.0/
@

<<label = initialize, echo = FALSE>>=

## remove several R objects in the global environment
rm(list = ls())

## create RData and Figures directory if necessary
suppressWarnings(dir.create("RData/"))
suppressWarnings(dir.create("Figures/"))

## set options
options(width=76,prompt="R> ", continue="+  ", useFancyQuotes = FALSE,
        digits = 3, scipen = 10)

## load required packages
library("vcrpart")
library("mlbench") 
library("partykit")
library("xtable")
library("Ecdat")
#library("RWeka")
library("rpart")

## load
load(file = "RData/vcrpart-applications.RData")
@

When carrying out a regression analysis, researchers often wish to know
whether and how moderating variables affect the coefficients of
predictor variables. For example, medical scientists may be interested
in how age or past illnesses moderate the effect of a clinical
trial \citep[e.g.,][]{Yusuf1991}, and social scientists may examine the
wage gap between genders separately for different labor sectors
and countries \citep[e.g.,][]{Arulampalam2007}.

\par

Varying coefficient models \citep[e.g.,][]{Hastie1993} provide a
semi-parametric approach for such moderated relations. Consider a
response variable $Y$, where $g(E(Y|\cdot)) = \eta$, with $g$ a known
link function and $\eta$ a predictor function of form:

\begin{equation}
  \mathcal{M}_{\text{vc}}: \eta =  X_{1} \beta_1 (\mathbf{Z}_{1}) +
  \ldots +  X_{P} \beta_P (\mathbf{Z}_{P})\enspace,
  \label{vcrpart-eq:basic}
\end{equation}
where the variables $X_p$, $p = 1, \ldots, P$, are the $P$ predictors
with each having a varying coefficient $\beta_p (\mathbf{Z}_{p})$. The
vector $\mathbf{Z}_p = (Z_{p1}, \ldots, Z_{pL_p})^T$ associated to
coefficient $\beta_p$ stands for the $L_p$ potential moderator
variables specified for that coefficient. Model~$\mathcal{M}_{\text{vc}}$
defines each coefficient $\beta_p$  as a multivariate,
nonparameterized function $\beta_p(\mathbf{Z}_{p})$ of its associated
set of moderators $\mathbf{Z}_{p}$. For example, if
$X_p$ is an indicator variable for some treatment and $Z_{p}$ reflects
the age, the term $\beta_p(Z_{p})$ states that the treatment effect
changes as a function of age. In principle, the moderator vectors
$\mathbf{Z}_1, \ldots, \mathbf{Z}_P$, can have common moderators and can
include some of the predictors $X_1, \ldots, X_P$. Model~$\mathcal{M}_{\text{vc}}$
also covers two special cases. First, defining $\mathbf{Z}_{p}$ as a
constant, for example by setting $\mathbf{Z}_{p}\equiv 1$, yields a
``non-varying'' coefficient for the predictor $X_p$. Second, for
a constant predictor $X_{p}\equiv 1$, the coefficient
$\beta_p(\mathbf{Z}_p)$ becomes a ``varying intercept'', and its
moderation provides a nonparametric estimate of the direct effects of
the moderators $\mathbf{Z}_{p}$ on $E(Y|\cdot)$.

\par

\label{vcrpart-sec:intro-discussion-moderator}
In varying coefficient regression, exogenous variables can act as
predictor, moderator or both. The distinction between predictor and
moderator arises naturally from the context. Predictors are the
variables for which we are primarily interested to study the
impact---coefficient---on the response variable. Moderators are
variables that we think can moderate the impact of predictors, i.e.,
variables with which the coefficients of predictors may vary. Such
moderators can serve to distinguish values of coefficients by groups
of cases, to model continuous evolution of coefficients, or simply to
improve the fit by allowing for interactions and
non-linearities. Different examples illustrate the use of moderators in sections~\ref{vcrpart-sec:evaluation} and~\ref{vcrpart-sec:applications}.
See for example \citet{Hayes2013} for a more in-depth discussion of
moderation.

\par

Various approaches have been considered to fit varying coefficient
models, in particular with spline or kernel regression methods. See
\cite{Fan2008} for an overview and the \proglang{R}
\citep{RCoreTeam2014} packages \pkg{mgcv} \citep{Wood2006}, \pkg{svcm}
\citep{Heim2007}, \pkg{mboost} \citep{Hothorn2014a}, and \pkg{np}
\citep{Hayfield2008} for software implementations. The
tree-based approach considered here is a combination of linear models
and recursive partitioning \citep[e.g.,][]{Quinlan1992, Alexander1996,
  Loh2002}, where \cite{Zeileis2005} and \cite{Wang2013} refer
explicitly to the use of recursive partitioning to fit models of the
form $\mathcal{M}_{\text{vc}}$ (\ref{vcrpart-eq:basic}). Thus, it
approximates the unknown varying coefficients with piecewise constant
functions using recursive partitioning. The tree-based approach has
certain drawbacks, particularly being a heuristic, and can be unstable
for small changes in the data. However, it does have several
advantages for statistical learning. Among others, the approach can
handle many moderators, interactions between moderators, and
nonlinearities, it treats moderators of different scales uniformly, and
yields easily readable outcomes in the form of decision trees.

\par

Both \cite{Zeileis2005} and \cite{Wang2013} propose approximating
$\mathcal{M}_{\text{vc}}$ as follows: Let $\mathbf{X} = (X_{1}, \ldots,
X_{P} )^{\top}$, $\mathbf{Z} = \{ \mathbf{Z}_1  \cup \ldots \cup
\mathbf{Z}_P \}$, and $\{\mathcal{B}_1, \ldots, \mathcal{B}_M \}$ be a
partition of the value space of the $\mathbf{Z}$ into $M$
strata. Then, their piecewise constant approximation has the
form

\begin{equation}
  \widehat{\mathcal{M}}_{\text{tree}}: \eta =
  \sum_{m=1}^M  1 \left(\mathbf{Z} \in \mathcal{B}_m \right)
    \mathbf{X}^{\top} {\boldsymbol\beta}_m\enspace.
  \label{vcrpart-eq:approx-1}
\end{equation}
Model $\widehat{\mathcal{M}}_{\text{tree}}$ (\ref{vcrpart-eq:approx-1}) is
linear and, consequently, standard estimation methods apply. The
nonparametric task is to find a partition such that the varying
coefficients $\beta_1(\mathbf{Z}), \ldots, \beta_P(\mathbf{Z})$ vary
between the strata $\{ \mathcal{B}_1, \ldots, \mathcal{B}_M \}$, but
are relatively constant within the strata. Since global partitioning
is computationally too challenging, forward-stepwise algorithms are used
that, in each iteration, split one of the current strata into two. The
resulting partition can be visualized as a decision tree and,
therefore, the strata $\mathcal{B}_m$ are referred to as terminal
nodes, or simply to as nodes.

\par

\label{vcrpart-sev:intro-tvcmform}
Here, we introduce the tree-based varying coefficient model (TVCM)
algorithm of the \proglang{R} package \pkg{vcrpart}
\citep{Burgin2014}. The TVCM algorithm allows us to approximate
$\mathcal{M}_{\text{vc}}$ in a ``coefficient-wise''
manner. First, assuming that $K$ out of the $P$ predictors have
varying-coefficients, we let $\mathbf{X}_0$ be the $P-K$ predictors
with non-varying coefficients and $X_1, \ldots, X_K$ denote the
remaining $K$ predictors with corresponding moderator vectors
$\mathbf{Z}_1, \ldots, \mathbf{Z}_K$. Further, we denote the value space
of $\mathbf{Z}_k$ as $\mathcal{Z}_k = \mathcal{Z}_{k1} \stimes \ldots
\stimes \mathcal{Z}_{kL_{k}}$ and denote a partition of $\mathcal{Z}_k$ into
$M_k$ nodes as $\{ \mathcal{B}_{k1}, \ldots, \mathcal{B}_{kM_k}
\}$. Then, the proposed approximation is:

\begin{equation}
  \widehat{\mathcal{M}}_{\text{tvcm}}: \eta =
  \mathbf{X}_{0}^{\top} {\boldsymbol\beta}_{0} +
  \sum_{k=1}^K\sum_{m=1}^{M_k}  1 \left(\mathbf{Z}_k \in
      \mathcal{B}_{km} \right) X_{k} \beta_{km}\enspace.
  \label{vcrpart-eq:approx-2}
\end{equation}
Compared with $\widehat{\mathcal{M}}_{\text{tree}}$, the TVCM
approximation $\widehat{\mathcal{M}}_{\text{tvcm}}$ assigns each
varying coefficient a partition and includes non-varying
coefficients. This allows us to specify parametrically known relations
(the first term) and coefficient-specific sets of moderators (the second
term). In addition, $\widehat{\mathcal{M}}_{\text{tvcm}}$ allows us to select
moderators individually by varying coefficient. Furthermore, empirical
evidence suggests (Sec.~\ref{vcrpart-sec:pima}) that
$\widehat{\mathcal{M}}_{\text{tvcm}}$ can build more accurate and
more parsimonious fits than $\widehat{\mathcal{M}}_{\text{tree}}$ is
able to do. A technical difference between the two approximations
$\widehat{\mathcal{M}}_{\text{tree}}$ and
$\widehat{\mathcal{M}}_{\text{tvcm}}$ is that the coefficients of
$\widehat{\mathcal{M}}_{\text{tree}}$ are commonly obtained by fitting a local model on each of the $M$ strata, while the approximation
$\widehat{\mathcal{M}}_{\text{tvcm}}$ must be fitted as a closed model on all observations.

\par

The remainder of this paper is organized as follows. In
Section~\ref{vcrpart-sec:algorithm}, we describe the basic algorithm
that we apply to generalized linear models. In
Section~\ref{vcrpart-sec:details}, we provide more detail and extend
the basic algorithm. The algorithm is evaluated in
Section~\ref{vcrpart-sec:evaluation} by comparing its performance
with competing algorithms on a benchmark data set and its ability
to retrieve an underlying generating model through a simulation study.
Then, in Section~\ref{vcrpart-sec:applications}, we present two
applications. Finally, the concluding Section~\ref{vcrpart-sec:conclusion}
addresses issues for further development.

\section{The TVCM algorithm}
\label{vcrpart-sec:algorithm}

Similar to classification and regression trees
\citep[CART,][]{Breiman1984}, TVCM involves two stages: The first
stage (Sec.~\ref{vcrpart-sec:partitioning}) builds $K$ overly
fine  partitions; the second stage (Sec.~\ref{vcrpart-sec:pruning})
 selects the final partitions by pruning.

\par

To provide a consistent formulation, we restrict our consideration of
TVCM to generalized linear models (GLMs). Therefore,
Section~\ref{vcrpart-sec:glm} summarizes GLMs and introduces an
illustrative example. Extensions to other model families are discussed
in Section~\ref{vcrpart-sec:extensions}.

\subsection{Generalized linear models}
\label{vcrpart-sec:glm}

GLMs cover regression models for various types of responses, such as
continuous data (the Gaussian model), count data (the Poisson model), and
binary data (the logistic model). Denote the $i$th
response of the training data $\mathcal{D}$ as $y_i$, with observations $i = 1,
\ldots, N$, and the $i$th $P \stimes 1$ predictor
vector as $\mathbf{x}_i$. Simple GLMs have densities of the form

\begin{equation}
  f(y_i | \theta_i, \phi) = \exp \left\{ \frac{y_i\theta_i -
      b(\theta_i)}{\phi} +  c(y_i, \phi) \right\}\enspace,
\end{equation}
where $\theta_i$ is the natural parameter of the family, $\phi$ is the
dispersion parameter, and $b(\cdot)$ and $c(\cdot)$ are family-specific
functions. For example, the Poisson distribution has density $f(y_i) =
\lambda_i^{y_i}e^{-\lambda_i}/k!$ and it can be derived that
$\theta_i = \log\lambda_i$, $b(\theta_i) = e^{\theta_i} = \lambda_i$,
$\phi = 1$, and $c(y_i, \phi) = \log y_i$. The predictor vector
$\mathbf{x}_i$ is incorporated by defining the linear predictor

\begin{equation}
  \mathcal{M}_{\text{glm}}: \eta_i = \mathbf{x}_i^{\top}
  {\boldsymbol\beta}\enspace,
\end{equation}
where ${\boldsymbol\beta}$ is the vector of unknown coefficients. This
linear predictor $\eta_i$ is linked with the conditional mean $\mu_i =
E(y_i | \mathbf{x}_i)$ via $g(\mu_i) = \eta_i = \mathbf{x}_i^{\top}
{\boldsymbol\beta}$. The choice of $g(\cdot)$ depends on the specific
model. A mathematically motivated choice is to specify $g(\cdot)$,
such that $\theta_i = \eta_i$, usually called canonical
  link. For example, for the Poisson model, the canonical is
$\log(\mu_i) = \eta_i$. Further details on GLMs can be found, for
instance, in \cite{McCullagh1983}.

\par

Generalized linear models are generally fitted using maximum
likelihood estimation (MLE), in other words, by maximizing the total
log-likelihood of the training data w.r.t. ${\boldsymbol\beta}$ and
$\phi$:

\begin{equation}
  \ell({\boldsymbol\beta}, \phi)
  = \sum_{i = 1}^N w_i \log f(y_i | {\boldsymbol\beta}, \phi)
  = \sum_{i=1}^N w_i \left( \frac{y_i\theta_i -
      b(\theta_i)}{\phi}  + c(y_i, \phi) \right)\enspace,
  \label{vcrpart-eq:glm-mle}
\end{equation}
where $w_i$ is the weight for observation $i$. The coefficients
${\boldsymbol\beta}$ enter into Equation~\ref{vcrpart-eq:glm-mle} via $\theta_i =
d(\mu_i)=d(g^{-1}(\mathbf{x}_i^{\top} {\boldsymbol\beta}))$, with
$d(\cdot)$ a known function. To fit GLMs, we use the \code{glm}
 function of the \pkg{stats} package \citep[see][]{Chambers1991}.

\paragraph{Gender gap in university admissions} To illustrate
\proglang{R} syntax and explanations, we consider the admission
data of the UC Berkeley from 1973. The data consist of $4,526$
observations on the response variable \code{Admit} (0 = rejected, 1 =
admitted) and the covariates \code{Female} (0 = male, 1 = female) and
\code{Dept} (departments $A$ to $F$). The training data \code{UCBA}
are prepared by

%TC:ignore
<<label = ucba-data>>=

UCBA <- as.data.frame(UCBAdmissions)
UCBA$Admit <- 1 * (UCBA$Admit == "Admitted")
UCBA$Female <- 1 * (UCBA$Gender == "Female")
head(UCBA, 3)
@
% TC:endignore
\label{code:data-UCBA}

Each row of the data \code{UCBA} represents one combination of values
in \code{Admit}, \code{Female}, and \code{Dept}. The column \code{Freq}
gives the frequencies of the combinations.%% \footnote{Descriptive
  %% statistics of this data set can be found in
  %% Table~\ref{vcrpart-appendix-tab:ucba-nominal}.}

\par

The UCB admission data are a popular application to illustrate
Simpson's paradox \citep[see][]{Bickel1975a}. The primary interest is
the gender gap in the chance to be admitted. Let us first study this
gap using the logistic regression model:

%TC:ignore
<<label = ucba-glmS, eval = TRUE>>=

glmS.UCBA <- glm(formula = Admit ~ Female, data = UCBA,
                 family = binomial(), weights = UCBA$Freq)
@
%TC:endignore
\label{code:glmS.UCBA}

The estimated coefficients,

%TC:ignore
<<label = ucba-glmS-coef, echo = TRUE>>=

summary(glmS.UCBA)$coefficients[, -4]
@
%TC:endignore

suggest that being female decreases
the logit to be admitted significantly (\textbar$z$~value\textbar $>2$). Now, let us extend the basic
model \code{glmS.UCBA} with the \code{Dept} covariate by defining
department-specific intercepts and department-specific gender gaps
(without a global intercept):

%TC:ignore
<<label = ucba-glmL, eval = TRUE>>=

glmL.UCBA <- glm(formula = Admit ~ -1 + Dept + Dept:Female,
                 data = UCBA, family = binomial(),
                 weights = UCBA$Freq)
@
%TC:endignore
\label{code:glmL.UCBA}

%TC:ignore
<<label = ucba-glmL-coef, echo = TRUE>>=

summary(glmL.UCBA)$coefficients[, -4]
@
%TC:endignore

\label{vcrpart-sec:glm-simpsonsparadox}
In this second fit, the disadvantage for females disappears, and, in
the case of department $A$, the gender gap is significantly positive
(\code{DeptA:Female}: Estimate
$=\Sexpr{round(coef(glmL.UCBA)["DeptA:Female"],2)}$, \textbar$z$~value\textbar
$>2$). The apparent disadvantage for females
in \code{glmS.UCBA} arises, as the reader may know, from the tendency of
females to apply to departments where the chances to be admitted are low.

\par

The model~\code{glmL.UCBA}, which uncovers the problem, can be seen as
a full parametric varying coefficient model that defines the intercept and
the gender gap as functions of the department. We will return to
this example to investigate whether and how TVCM solves this problem.

\subsection{Partitioning}
\label{vcrpart-sec:partitioning}

The first stage to fit the approximate varying coefficient model
$\widehat{\mathcal{M}}_{\text{tvcm}}$ (\ref{vcrpart-eq:approx-2})
involves building a partition for each of the value spaces
$\mathcal{Z}_k$, $k = 1, \ldots, K$ corresponding to the $K$ varying
coefficients. The resulting $K$ partitions should be overly fine so
that the `optimal' partitions can be found in the subsequent pruning
stage. Algorithm~\ref{vcrpart-alg:partitioning} provides a formal
summary of this partitioning algorithm.

\begin{algorithm}[t]
  \DontPrintSemicolon
  % \caption[TVCM partitioning algorithm]{The TVCM partitioning algorithm for generalized linear models.}
  \caption{The TVCM partitioning algorithm for generalized linear models.}
  \label{vcrpart-alg:partitioning}
  \SetAlgoLined
  \BlankLine
  \SetKwInOut{Input}{Parameters}
  \Input{
    \begin{tabular}[t]{ll}
      $N_0$ & minimum node size, e.g., $N_0=30$ \\
      $D_{min}$  & minimum $-2\cdot\text{log-likelihood}$
    reduction, e.g., $D_{min} = 2$ \\
    \end{tabular}
    }
  Initialize $\mathcal{B}_{k1} \gets \mathcal{Z}_{k1} \stimes
  \ldots \stimes \mathcal{Z}_{kL_k}$ and $M_k \gets 1$ for all partitions $k = 1,
  \ldots, K$. \\
  \Repeat{no candidate split satisfies $N_0$
    or $D_{k'm'l'j'} < D_{min}$}{
    \nl Compute $\hat{\ell}^{\widehat{\mathcal{M}}} =
    \displaystyle\max_{\{{\boldsymbol\beta},
      \phi\}}\ell^{\widehat{\mathcal{M}}}({\boldsymbol\beta},
      \phi)$ of the current model
    \begin{equation}
      \widehat{\mathcal{M}}:\eta_i =
      \mathbf{x}_{i0}^{\top} {\boldsymbol\beta}_{0} +
      \sum_{k=1}^K\sum_{m=1}^{M_k}  1 \left(\mathbf{z}_{ik} \in \mathcal{B}_{km} \right)
      x_{ik}\beta_{km}\enspace.
      \label{vcrpart-eq:alg}
    \end{equation}
    using all observations $i = 1, \ldots, N$.\\
    \For{partitions $k = 1$ to $K$}{
       \For{nodes $m = 1$ to $M_k$ and moderator variables $l = 1$ to $L_k$}{
         \ForEach{unique candidate split $\vartriangle_{kmlj}$,
           in $\{z_{kli}: \mathbf{z}_{ik} \in \mathcal{B}_{km}\}$ that divides
          $\mathcal{B}_{km}$ into two nodes $\{\mathcal{B}_{kmlj1},
          \mathcal{B}_{kmlj2}\}$ and satisfies  $\min_{s} \sum_{i} w_i
          1(\mathbf{z}_{ik} \in \mathcal{B}_{kmljs})  \ge N_{0}$}{
       \nl Using only the observations
       $\{i: \mathbf{z}_{ik} \in\mathcal{B}_{km}\}$ of the
       node $\mathcal{B}_{km}$, compute
      $\hat{\ell}^{\widehat{\mathcal{M}}_{kmlj}} =
       \displaystyle\max_{\{\beta_{1}, \beta_{2},
         \phi\}}\ell^{\widehat{\mathcal{M}}_{kmlj}}( \beta_{1}, \beta_{2}, \phi)$
      of the approximate search model
      \begin{equation}
         \widehat{\mathcal{M}}_{kmlj}: \eta_i ^{(s)} = \hat{\eta}_i +
        \sum_{s=1}^2 1 \left(\mathbf{z}_{ik} \in \mathcal{B}_{kmljs}  \right)
        x_{ik} \beta_{s}\enspace,
        \label{vcrpart-eq:alg-search}
      \end{equation}
      and  compute the training error reduction $D_{kmlj} =
      -  2 \hat{\ell}^{\widehat{\mathcal{M}}} +
      2\hat{\ell}^{\widehat{\mathcal{M}}_{kmlj}}_{\{i: \mathbf{z}_{ik} \in\mathcal{B}_{km}\}}$, \\
      where $\hat{\ell}^{\widehat{\mathcal{M}}}_{\{i: \mathbf{z}_{ik} \in\mathcal{B}_{km}\}}$ is the
   subtotal of $\hat{\ell}^{\widehat{\mathcal{M}}}$ for the observations of  $\mathcal{B}_{km}$.
    } }
   }

   \nl Split node $\mathcal{B}_{k'm'} $ by
   $\vartriangle_{k'm'l'j'}$ where $D_{k'm'l'j'} = \max D_{kmlj}$
   and increase $M_{k'} \gets M_{k'} + 1$. \;
}
\end{algorithm}

\label{vcrpart-par:partitioning-summary}
To partition the value spaces $\mathcal{Z}_1, \ldots, \mathcal{Z}_K$,
Algorithm~\ref{vcrpart-alg:partitioning} uses a breadth-first search
\citep[e.g.,][]{Russell2003} that in each iteration fits the current
model and splits one of the current terminal nodes into two. The split
is selected by employing an exhaustive search over a set of candidate
splits. These candidate splits are denoted by $\vartriangle_{kmlj}$
and refer in each case to a partition $k$; a node $m$; a moderator
variable $l$; and the cutpoint $j$ in the selected
moderator. Algorithm~\ref{vcrpart-alg:partitioning} fits for each
candidate split a corresponding (approximate) search-model
$\widehat{\mathcal{M}}_{kmlj}$ (\ref{vcrpart-eq:alg-search}) and
selects the split that reduces the total
$-2\cdot\text{log-likelihood}$ training error the most.%
\footnote{In
  other words, we maximize the deviance from
  the current model.}
The used search-model is approximate in that it keeps, in step 2, all
parameters but those of the two newly created nodes as fixed, and it uses
only the observations of the node to split. The reason for that is
given below under `Computational Details' on
page~\pageref{vcrpart-sec:partitioning-comp-details}. The algorithm
iterates until (i) no candidate split provides daughter nodes with
more than $N_0$ observations or (ii) the best split increases the
$-2\cdot\text{log-likelihood}$ training error by less than $D_{min}$.

\par

\label{vcrpart-par:selection-bias}
When searching for a split, there can be differences in the number of
candidate splits between partitions, nodes, and potential moderators. The
$-2\cdot\text{log-likelihood}$ reduction statistic is not
`standardized' to such differences and, therefore,
Algorithm~\ref{vcrpart-alg:partitioning} tends to select partitions, nodes, and
variables with many candidate splits \citep[cf.,][]{Hothorn2006}. This selection
bias negatively affects interpretability and accuracy of the resulting trees.
%As
%the main consequence, the order in which variables appear in the trees
%should be interpreted carefully.
Reducing this bias is desirable and,
therefore, a potential focus for further investigations.

\paragraph{The \code{tvcglm} function} The \code{tvcglm} function
implements Algorithm~\ref{vcrpart-alg:partitioning}. For illustration, we fit
a logistic TVCM to the UCB admission data. The following command
specifies that both the intercept and the gender gap vary across
departments.


%TC:ignore
<<label = ucba-fitting-vcmL, eval = TRUE>>=

library("vcrpart")
vcmL.UCBA <-
  tvcglm(formula = Admit ~ -1 + vc(Dept) + vc(Dept, by = Female),
         data = UCBA, family = binomial(), weights = UCBA$Freq,
         control = tvcglm_control(minsize = 30, mindev = 0.0,
           cv = FALSE))
@
%TC:endignore
\label{code:vcmL.UCBA}

\code{tvcglm} treats the \code{data}, \code{family} and
\code{weights} arguments in the same way as \code{glm}.
Varying coefficients are specified with the `\code{vc}' operator and
a separate partition is fitted for each \code{vc} term. The \code{by}
argument of the \code{vc} operator specifies the predictor, while
potential moderators are specified before the \code{by} argument as a
comma separated list of variables. When no \code{by} argument is
given, the \code{vc} term defines a varying intercept. Non-\code{vc}
terms are treated as linear terms, as in \code{glm}. In the example
above, `\code{vc(Dept)}' specifies a intercept varying with the variable
\code{Dept}, and `\code{vc(Dept, by = Female)}' a varying coefficient
for \code{Female} that varies with \code{Dept}. The predictors passed
as \code{by} argument must be numeric in the current
implementation. This is why we have defined
(page~\pageref{code:data-UCBA}) the \code{Female} variable for the
\code{UCBA} data as
`\code{UCBA\$Female  <-  1 * (UCBA\$Gender ==  "Female")}'.

\par

The control parameters are set by the \texttt{tvcglm\_control}
function. Above, `\code{minsize = 30}' specifies $N_0=30$ and
`\code{mindev = 0}' specifies $D_{min}=0$. We set $D_{min}=0$ to obtain
the largest possible tree and `\code{cv = FALSE}' to disable
cross-validation (Sec.~\ref{vcrpart-sec:pruning}). Note that
practice-oriented examples follow in
sections~\ref{vcrpart-sec:evaluation} and~\ref{vcrpart-sec:applications}, and details on arguments and
dummy examples can be found in the help pages of the functions
\code{tvcglm}, \code{vc} and \texttt{tvcglm\_control}.

\begin{figure}[!ht]
  \centering
  \setkeys{Gin}{width=1\textwidth}

<<label = ucba-fig-vcmL, fig = TRUE, echo = FALSE, width = 10, height = 6.5>>=

grid.newpage()
pushViewport(viewport(layout = grid.layout(1, 2)))
pushViewport(viewport(layout.pos.col = 1))
plot(vcmL.UCBA, part = 1, type = "coef", newpage = FALSE)
upViewport()
pushViewport(viewport(layout.pos.col = 2))
plot(vcmL.UCBA, part = 2, type = "coef", newpage = FALSE)
upViewport()
upViewport()
@
\caption[\code{UCBA} data: Fit from the partitioning
stage]{\code{vcmL.UCBA}: Fitted tree structures and nodewise
  coefficients. Left panel: The varying intercept. Right panel: The
  varying gender gap.}
\label{fig:UCBA-large}
\end{figure}

The two fitted partitions are shown in Figure~\ref{fig:UCBA-large},
along with the nodewise coefficients. These plots were produced by the
following commands:

%TC:ignore
<<label = ucba-plot, eval = FALSE>>=

plot(vcmL.UCBA, type = "coef", part = "A")
plot(vcmL.UCBA, type = "coef", part = "B")
@
%TC:endignore

As an option,\footnote{See the \code{conf.int} argument of
  the \texttt{panel\_coef} function.}, we could display the confidence intervals
extracted from the underlying \code{glm} object. However, these
intervals would not account for the model selection procedure and we
do not show them here. Both partitions separate the departments fully
and, therefore, the values of the coefficients of \code{vcmL.UCBA}
shown in Figure~\ref{fig:UCBA-large} are exactly those obtained for
the model \code{glmL.UCBA} on page~\pageref{code:glmL.UCBA}. The
partitioning process can be backtracked using the \code{splitpath}
function. The following command summarizes the first iteration.

\label{cmd:splitpath}
%TC:ignore
<<label = ucba-splitpath>>=

splitpath(vcmL.UCBA, steps = 1, details = TRUE)
@
%TC:endignore

Based on the training error reduction statistic $D_{kmlj}$ (column
\code{dev}), the algorithm selects the split $\{ F\}$ vs $\{ A, B, C,
D, E\}$ for the varying intercept (partition A). The evaluated splits,
listed in the lower part, show that only a subset of possible splits
was evaluated. For example, the split $\{A, F\}$ vs $\{B, C, D\}$ was
excluded from the search. This relates to the implemented acceleration
technique that orders the six categories $A$ to $F$ and treats the
\code{Dept} as ordinal (details follow).

\subsubsection{Computational details}
\label{vcrpart-sec:partitioning-comp-details}

A breadth-first search can be computationally burdensome because it
cycles in each iteration through all current nodes. Even so, we do not
consider a depth-first search, which is more common for recursive
partitioning and which evaluates only one node in each iteration,
because it seems unclear whether the search sequence has consequences
on the resulting partitions. To speed up the search, we use the
approximate search model $\widehat{\mathcal{M}}_{kmlj}$
(\ref{vcrpart-eq:alg-search}) to compute the training error
reduction of split $\vartriangle_{kmlj}$, instead of using the
following accurate search model

\begin{multline}
  \widehat{\mathcal{M}}^{*}_{kmlj}: \eta_i^{(s)} =
  \mathbf{x}_{i0}^{\top} {\boldsymbol\gamma}_{0} +
  \sum_{(k',m') \neq (k,m)}  1\left(\mathbf{z}_{k'i} \in \mathcal{B}_{k'm'} \right)
  x_{k'i} \gamma_{k'm'}\; + \\
  +\;\sum_{s=1,2}  1 \left(\mathbf{z}_{ik} \in \mathcal{B}_{kmljs}  \right)
  x_{ik} \gamma_{s}\enspace.
  \label{vcrpart-eq:search}
\end{multline}
The accurate search model, $\widehat{\mathcal{M}}^{*}_{kmlj}$
(\ref{vcrpart-eq:search}), requires using all observations $i = 1,
\ldots, N$ and re-estimating all coefficients. By
contrast, the approximate search model,
$\widehat{\mathcal{M}}_{kmlj}$, uses only the observations $\{i:
\mathbf{z}_{ik} \in \mathcal{B}_{km}\}$ of the node to split
and incorporates the fitted values $\hat{\eta}_i$ of the current model
$\widehat{\mathcal{M}}$ (\ref{vcrpart-eq:alg}) as offsets. This
reduces the optimization per considered split to three parameters,
namely the coefficients $\beta_1$ and $\beta_2$ of the newly created
nodes, and the dispersion parameter $\phi$, because it cannot be fixed
in \code{glm}. More specifically, the approximate model
$\widehat{\mathcal{M}}_{kmlj}$ estimates the coefficients $\gamma_s$,
$s = 1,2$ of $\widehat{\mathcal{M}}^{*}_{kmlj}$ as $\hat{\gamma_s} =
\hat{\beta}_{km} + \hat{\beta}_s$, with $\hat{\beta}_{km}$ retrieved
from the current model $\widehat{\mathcal{M}}$. Further, in
$\widehat{\mathcal{M}}_{kmlj}$ all the remaining coefficients of
$\widehat{\mathcal{M}}^{*}_{kmlj}$, i.e., ${\boldsymbol\gamma}_0$ and
$\gamma_{k'm'}$ for $(m',k')\neq(m,k)$, are
kept fixed at the values estimated in part~1 (\ref{vcrpart-eq:alg}).
In our experience,
the approximation is reliable, although it does not necessarily result in the same
partitions that the accurate search would produce.%
\footnote{The approximation can be disabled by setting `\code{fast = FALSE}' in
  \code{tvglm\_control()}.}
In particular, the approximation will
tend to neglect splits that improve the fit through interplays with
the temporarily fixed coefficients.

\par

Eliminating split candidates and cleverly choosing the stopping
parameters are further efficient acceleration techniques. We describe
these techniques in more detail here.

\paragraph{Splits for ordered scales} In
Algorithm~\ref{vcrpart-alg:partitioning}, the splits $\vartriangle_{kmlj}$ for
continuous and ordinal moderators are defined as rules of the form
$\{\text{Is }z_{kli} \le \zeta_{kmlj}\text{?}\}$. The candidate
cutpoints, $\{\zeta_{kml1},\ldots \}$, are the unique values in set
$\{z_{kli}: \mathbf{z}_{ik} \in \mathcal{B}_{km} \}$. Note that splits
at boundaries may be omitted to respect the minimum node size
criterion. To reduce the computational burden, we allow the set of
candidate cutpoints to shrink to a prespecified cardinality $N_S$,
which is $N_S = 9$ by default.\footnote{See the \code{maxnumsplit}
  and \code{maxordsplit} arguments in \code{tvcglm\_control}.}
Specifically, the unique values of the (non-interpolated) quantiles of
$\{z_{kli}: \mathbf{z}_{ik} \in \mathcal{B}_{km}\}$ are extracted at
the $N_S$ equidistant probabilities $(1, \ldots, N_S) / (N_S + 1)$. In
cases of tied data, where this procedure potentially yields fewer than
$N_S$ splits, the number of equidistant probabilities is increased
until the set of candidate splits has the desired size.

\label{vcrpart-par:nominal-splits}
\paragraph{Splits for nominal scales} The splits $\vartriangle_{kmlj}$
for nominal moderators are rules of the form $\{\text{Is }z_{kli} \in
\zeta_{kmlj}\text{?}\}$, where $\zeta_{kmlj}$ are merged categories
from the set $\{z_{kli}: \mathbf{z}_{ik} \in \mathcal{B}_{km}\}$. The
number of unique candidate merges for $C$ categories is $2^{C-1}$,
which increases exponentially with $C$. An approximation that
restricts the number of splits to be linearly increasing with $C$
determines a category order and then treats the moderator as ordinal. For
CART, \cite{Breiman1984} propose to deduce such an order from the category-wise averages in
the current node. Following this idea, we
propose ordering, for each node, the categories by the category-wise estimated
coefficients. This reduces the computational expenses to fitting the
model that provides the category-wise coefficients, and fitting the
at most $C-1$ models that evaluate the ordinal splits. By default,
the approximation is applied for $C \ge 5$.%
\footnote{See the
  \code{maxnomsplit} argument in \code{tvcglm\_control}. After the
  transformation to the ordinal scale, the argument \code{maxordsplit}
  controls the effective number of evaluated splits.}

\par

On page~\pageref{cmd:splitpath}, we referred to the category ordering
technique when demonstrating the \code{splitpath} function for the
first iteration of partitioning. For instance, for partition B (the
gender gap), we used the order $F < E < C < D < B < A$. The rank of a
category corresponds to the first row where a `\code{1}'
appears in the corresponding column. The category-wise coefficients can be estimated by using the
model:

%TC:ignore
<<label = ucba-nomsplits-fitting>>=

glmCW.UCBA <-
  glm(formula = Admit ~ 1 + Dept:Female, family = binomial(),
      data = UCBA,  weights = UCBA$Freq)
@
%TC:endignore

The model \code{glmCW.UCBA} substitutes the effect of \code{Female} of
the current model, which is just the model \code{glmS.UCBA}
(page~\pageref{code:glmS.UCBA}), by an interaction term with
\code{Dept} and \code{Female}. The category ordering is then obtained
by ordering the estimated department-specific gender effects.

%TC:ignore
<<label = ucba-nomsplits-coef>>=

sort(coef(glmCW.UCBA)[-1])
@
%TC:endignore

Internally, our implementation uses an approximation technique to
estimate category-wise coefficients, which is analogous to the
technique used for approximating the search model
$\widehat{\mathcal{M}}^{*}_{kmlj}$ (\ref{vcrpart-eq:search}). %% See
%% Appendix~\ref{vcrpart-appendix-sec:category-ordering} for the
%% details.

\label{vcrpart-par:stopping}
\paragraph{Stopping criteria} Algorithm~\ref{vcrpart-alg:partitioning} applies
two stopping criteria. First, to have sufficient observations to
estimate the coefficients nodewise, we require a minimum
node size $N_0$. Here, $N_0=30$ seems a reasonable rule of thumb
value, but can be modified according to the model. Second, to reduce
the computational burden, we stop partitioning as soon as the maximal
training error reduction falls below $D_{min}$. Large values of
$D_{min}$ yield rougher partitions and require less computation, and
vice versa. Therefore, it is crucial to choose $D_{min}$ to be small
enough so that the optimal partitions are not overlooked. The default
$D_{min}=2$ was selected based on the forward-stepwise AIC algorithm
\citep[e.g.,][]{Venables2002}, which also requires the total
$-2\cdot\text{log-likelihood}$ training error to decrease by at least
2 to continue. In our experience, $D_{min}=2$ is small enough to
capture the optimal partition, yet reduces the computational burden
considerably. In Section~\ref{vcrpart-sec:pima}, we evaluate the
impact of $N_0$ and $D_{min}$ on a real data application.

\par

The \texttt{tvcglm\_control} function also allows us to control
classic tree growth parameters. These parameters, which can
include the maximum number of terminal nodes and the maximal depth of
the trees, can restrict the complexity of the final model.

\subsection{Pruning}
\label{vcrpart-sec:pruning}

The pruning stage selects the final model by collapsing the inner
nodes of the overly fine partitions produced by
Algorithm~\ref{vcrpart-alg:partitioning}. In other words, it cuts branches
stemming from the same node. Here, we broadly follow the minimal
cost-complexity pruning approach of
\citet[][Chap.~8]{Breiman1984}. Let $\widehat{\mathcal{M}}$ be a
fitted model of form Equation~\ref{vcrpart-eq:approx-2}, where the nodes
$\mathcal{B}_{km}$ result from
Algorithm~\ref{vcrpart-alg:partitioning}. Define the cost-complexity error
criterion by

\begin{equation}
  \text{err}_{\lambda} (\widehat{\mathcal{M}}) :=
  -2 \hat{\ell}^{\widehat{\mathcal{M}}} +
   \lambda \sum_{k=1}^{K} (M_k^{\widehat{\mathcal{M}}} - 1),\enspace
   \lambda \ge 0\enspace.
  \label{vcrpart-eq:pe}
\end{equation}

In other words, we define the criterion as the total $-2
\cdot\text{log-likelihood}$ training error plus a tuning constant
$\lambda$ multiplied by the total number of splits. Here, $\lambda$
trades off the in-sample performance and the complexity (i.e., the
number of splits) of the model. When minimizing $\text{err}_{\lambda}
(\widehat{\mathcal{M}})$, small choices of $\lambda$ yield models with many
splits, and vice versa. In general, $\lambda$ is unknown and must be
chosen adaptively from the data.

\paragraph{Pruning algorithm} Pruning hierarchically collapses inner
nodes of the initially overly fine partition to find the model that
minimizes $\text{err}_{\lambda} (\widehat{\mathcal{M}})$, given
$\lambda$. A global search that collapses multiple inner nodes
simultaneously would be computationally too expensive and, therefore,
we adopt the weakest link pruning algorithm of
\citep{Breiman1984}. Algorithm~\ref{alg:pruning} summarizes the
implemented algorithm.

\begin{algorithm}[t]
  \DontPrintSemicolon
  % \caption[TVCM pruning algorithm]{The TVCM weakest-link pruning algorithm for generalized linear models.}
  \caption{The TVCM weakest-link pruning algorithm for generalized linear models.}
  \label{alg:pruning}
  \KwIn{A fitted model $\widehat{\mathcal{M}}$ from
    Algorithm~\ref{vcrpart-alg:partitioning}}
  \SetKwInOut{Input}{Parameters}
  \Input{
    \begin{tabular}{ll}
      $\lambda$: & the cost-complexity penalty, $\lambda \ge 0$ \\
    \end{tabular}
    }
  \Repeat{all $\bar{D}_{kj} > \lambda$}{
    \ForAll{inner nodes $\mathcal{B}_{kj}^*$ of
      $\widehat{\mathcal{M}}$, $k = 1, \ldots, K$ and $j = 1, \ldots,
      M_k - 1$
    }{
      Fit the model $\widehat{\mathcal{M}}_{kj}$ that collapses the
      inner node $\mathcal{B}_{kj}^*$ of $\widehat{\mathcal{M}}$. \;
      Compute the per-split increase of the training error $\bar{D}_{kj} =
      \frac{
        - 2 \hat{\ell}^{\widehat{\mathcal{M}}_{kj}}
        + 2 \hat{\ell}^{\widehat{\mathcal{M}}}
      }{
      \sum_{k} M^{\widehat{\mathcal{M}}}_k  - \sum_{k} M^{\widehat{\mathcal{M}}_{kj}}_k }$.\;
    }
    \If{any $\bar{D}_{kj} \le \lambda$}{
      Set $\widehat{\mathcal{M}} \gets \widehat{\mathcal{M}}_{k'j'}$
      with $\{k',j'\} = \arg\min_{{k,j}} \bar{D}_{kj}$}
    }
\end{algorithm}

Each iteration in Algorithm~\ref{alg:pruning} collapses the inner node
that yields the smallest per-split increase in the total $-2 \cdot
\text{log-likelihood}$ training error. The procedure starts with the
model from the partitioning stage and continues until the smallest
per-split increase is larger than $\lambda$ (i.e., all remaining
collapses would increase $\text{err}_{\lambda} (\widehat{\mathcal{M}})$). The
\code{prune} function implements Algorithm~\ref{alg:pruning}. For
example, the fit for \code{vcmL.UCBA} on page~\pageref{code:vcmL.UCBA}
is pruned with $\lambda=6$, as follows.

%TC:ignore
<<label = ucba-prune-fixed-lambda>>=

vcm.UCBA <- prune(vcmL.UCBA, cp = 6)
@
%TC:endignore

The pruning algorithm can be backtracked with the \code{prunepath}
function.

%TC:ignore
<<label = ucba-prunepath>>=

prunepath(vcm.UCBA, steps = 1)
@
%TC:endignore

The above \proglang{R} output provides various information about the first
iteration of Algorithm~\ref{alg:pruning}, applied on the fit for
\code{vcmL.UCBA}. The columns \code{part} and \code{node} identify the
collapsed inner node, and \code{dev} shows the per-split increase of
the training error. In the first iteration, the inner node 8 of
partition B (the gender gap) yields the smallest $\bar{D}_{kj}$ and is
therefore collapsed.

\paragraph{Choosing $\lambda$}
\label{rep-5-fold-cv}
The per-split penalty $\lambda$ is
generally unknown and, hence, must be chosen adaptively from the
data. To do so, the validation-set or cross-validation methods are
suitable \citep[e.g.,][]{Breiman1984} and computationally fast. The validation-set method works as
follows. First, divide the training data $\mathcal{D}$ randomly into a
subtraining set $\mathcal{D}_1$ and a validation set $\mathcal{D}_2$,
e.g., with a ratio of $3:1$. Second, replicate the fit with
Algorithm~\ref{vcrpart-alg:partitioning} based on $\mathcal{D}_1$. Third,
repeatedly prune the new fit with increasing $\lambda$ values and
compute the validation error each time an inner node is
collapsed. This yields two sequences, $\{ \lambda_1 = 0, \ldots,
\lambda_S, \lambda_{S+1} = \infty\}$ and
$\{\overline{\text{err}}^{\mathcal{D}_2}_1, \ldots,
\overline{\text{err}}^{\mathcal{D}_2}_S\}$, where
$\overline{\text{err}}^{\mathcal{D}_2}_s = \frac{-2}{\sum_{i \in
    \mathcal{D}_2} w_i}\sum_{i \in  \mathcal{D}_2}  w_i \log{
  f_{\widehat{\mathcal{M}}}(y_i | \mathbf{x}_i, \mathbf{z}_i)}$ is the
average\footnote{We use the average to avoid having the validation
  error depend on the number of observations in $\mathcal{D}_2$.}
prediction error on $\mathcal{D}_2$ of the new model pruned by
$\lambda$ values in interval $\left[ \lambda_s, \lambda_{s+1}
\right)$. We retain the estimate for $\lambda$,

\begin{equation}
  \hfill
\hat{\lambda} = \frac{\lambda_{s'} + \lambda_{s'+1}}{2}
\enspace\enspace\enspace\enspace\text{with}\enspace\enspace\enspace\enspace
\hfill s' = \arg\min_{s \in \{ 1, \ldots, S\} }
\overline{\text{err}}^{\mathcal{D}_2}_{s}\enspace.
\hfill
\label{vcrpart-eq:lambda}
\end{equation}
This is the center of the interval $\left[ \lambda_{s'},
  \lambda_{s'+1} \right)$ that minimizes the validation error
$\overline{\text{err}}^{\mathcal{D}_2}$. The estimation potentially
yields $\hat{\lambda} = \infty$, in which case no split is
necessary. Cross-validation methods repeat the validation-set method
to include the entire data. In particular, cross-validation combines
the obtained sequences $\{ \lambda_1, \ldots, \lambda_{S+1}\}$ to a
finer grid and averages the errors
$\overline{\text{err}}^{\mathcal{D}_2}_s$ accordingly.

\par

The \code{cvloss} function implements the validation-set and the
cross-validation methods to estimate $\hat{\lambda}$. By default,
5-fold cross-validation is used. To estimate $\lambda$ for the
\code{UCBA} data, we use the commands:

%TC:ignore
<<label = ucba-cv, eval = FALSE>>=

cv.UCBA <- cvloss(vcmL.UCBA,
                  folds = folds_control(weights = "freq", seed = 13))
@
%TC:endignore

The argument `\code{weights = "freq"}' indicates that the weights of
\code{vcmL.UCBA} represent counts rather than unit-specific weights
(default). The \code{seed} argument is used to control the random
generator when creating the cross-validation folds, which allows the
results to be replicated. If available, the \code{cvloss} function
processes the validation sets parallelized.

\begin{figure}[tbp]
  \centering
  \setkeys{Gin}{width=0.35\textwidth}

<<label = ucba-fig-cv, echo = FALSE, fig = TRUE, width = 3.25, height = 3>>=

par(mgp = c(2, 1, 0), mar = c(3,3,0.1,0.1))
plot(cv.UCBA,
     xlab = expression(lambda),
     ylab = "Validation error",
     legend = FALSE)
@
\caption[\code{UCBA} data: 5-fold cross-validated error]{\code{cv.UCBA}:
  Validation errors in function of $\lambda$ from 5-fold
  cross-validating fits for \code{vcmL.UCBA}. Black solid
  line: The cross-validated error. Gray solid lines: The
  validation errors on individual validation sets. Vertical
  dotted line: The estimated value for $\lambda$.}
\label{fig:UCBA-cv}
\end{figure}

<<label = ucba-lambda, echo = FALSE>>=

oobLoss <- colMeans(cv.UCBA$oobloss)
subs <- which.min(oobLoss)
cp.hat <- cv.UCBA$cp.hat
cp.int <- cv.UCBA$grid[subs:(subs+1)]
@

The black solid line in Figure~\ref{fig:UCBA-cv} shows the per-split
penalty $\lambda$ against the cross-validated error of fits for
\code{vcmL.UCBA}, which is minimal with
$\overline{\text{err}}^{\text{cv}}_{\Sexpr{subs}} = \Sexpr{round(oobLoss[subs],3)}$
at $\hat{\lambda}=\Sexpr{format(cv.UCBA$cp.hat, digits =  2)}$. The
original fit for~\code{vcm.UCBA} can be pruned by
$\hat{\lambda} = \Sexpr{format(cv.UCBA$cp.hat,digits =  2)}$ with the
command:

%TC:ignore
<<label = ucba-prune-estimated-lambda, eval = FALSE>>=

vcm.UCBA <- prune(vcmL.UCBA, cp = cv.UCBA$cp.hat)
@
%TC:endignore

\begin{figure}[!ht]
  \centering
  \setkeys{Gin}{width=1\textwidth}

<<label = ucba-fig-vcm, fig = TRUE, echo = FALSE, width = 10, height = 5>>=

grid.newpage()
pushViewport(viewport(layout = grid.layout(1, 2, width = c(0.5, 0.5))))
pushViewport(viewport(layout.pos.col = 1))
plot(vcm.UCBA, part = 1, newpage = FALSE, type = "coef")
upViewport()
pushViewport(viewport(layout.pos.col = 2))
plot(vcm.UCBA, part = 2, newpage = FALSE, type = "coef")
upViewport()
upViewport()

@
\caption[\code{UCBA} data: Fit from pruning]{\code{vcm.UCBA}:
  Pruned tree structures and nodewise coefficient plots. Left
  panel: The varying intercept. Right panel: The varying
  gender gap.}
\label{fig:UCBA-pruned}
\end{figure}

The varying coefficients of the model obtained from pruning with
$\hat{\lambda} = \Sexpr{format(cv.UCBA$cp.hat, digits = 2)}$ are shown
in Figure~\ref{fig:UCBA-pruned}. Both the varying intercept and
the varying gender gap are split into three strata. The final model
collapses several departments. For example, in the right panel, we see that
the departments $B$, $C$, $D$, and $F$ share the same gender gap. By
contrast, the large negative intercept in department $F$ and the large
gender gap in department $A$ remain detached.

\par

Alternatives to $\hat{\lambda}$ (\ref{vcrpart-eq:lambda}) could be
considered. For example, \citet[][Chap.~3]{Breiman1984} propose the 1-SE
rule to decrease the variance of $\hat{\lambda}$. We prefer
$\hat{\lambda}$ for its simple form, but with \code{cvloss} and
\code{prune}, we provide the tools to use these alternative rules.

\section{Details and extensions}
\label{vcrpart-sec:details}

In Section~\ref{vcrpart-sec:algorithm}, we explained the basic parts
of the TVCM algorithm. This section describes the algorithm in more
detail and explains how TVCM can be extended to other model classes.


\subsection{Mean-centering the predictors of the search model}
\label{vcrpart-sec:variable-centering}

A useful technique to improve the split selection with the
approximate search model~$\widehat{\mathcal{M}}_{kmlj}$
(\ref{vcrpart-eq:alg-search}) is to mean-center its
predictors. That is, we substitute the values $x_{ik}$ in
Equation~\ref{vcrpart-eq:alg-search} with the values $\tilde{x}_{ik} =
x_{ik} - N^{-1} \sum_{i=1}^N x_{ik}$. The advantage of this is most
visible in the case of a pure interaction. Consider
Figure~\ref{fig:centering}. In both panels the slope of a predictor
$x$ varies between two groups, A and B. In the left panel, the TVCM
partitioning algorithm tries to uncover this
moderation when $x$ is not centered and the current model specifies a
global intercept and a global slope for $x$. The search model uses the
fitted values of the current model (solid line) as offsets and
incorporates separate slopes for each group. This restricts the slopes
to pass through the origin, and hence the fit (dotted and dashed
lines) do not really identify the moderation pattern. The right panel
shows that, in this scenario, the moderation pattern is perfectly
identified by using the same search procedure, but when $x$ is
mean-centered.

\begin{figure}[!ht]
  \centering
  \setkeys{Gin}{width=0.8\textwidth}

<<label = details-mean-centering, echo = FALSE, fig = TRUE, height = 4, width = 9>>=

set.seed(1)
d <- data.frame(x = runif(100, min = -5, max = 5),
                g = rep(LETTERS[1:2], each = 50))
d$y <- model.matrix(~ -1 + g:x, d) %*% c(-1, 1) + rnorm(100)
d$x <- d$x + 10
d$x.centered <- d$x - mean(d$x)
par(mfrow = c(1, 2), mgp = c(2,1,0), mar = c(3,3,2,3), cex.main = 1.25)
lm <- lm(y ~ x, d)
d$offset <- lm$coefficients[1]
lmA <- lm(y ~ -1 + x, d, subset = d$g == "A", offset = d$offset)
lmB <- lm(y ~ -1 + x, d, subset = d$g == "B", offset = d$offset)
plot(y ~ x, d, pch = as.integer(d$g)^2, xlim = c(-5, 15),
     main = "x not mean-centered")
legend("topleft", c("Global", "Group A", "Group B"), lty = 1:3, pch = c(NA, 1, 4))
abline(lm, lty = 1)
abline(a = coef(lm)[1], b = coef(lmA), lty = 2)
abline(a = coef(lm)[1], b = coef(lmB), lty = 3)
lm <- lm(y ~ x.centered, d)
d$offset <- lm$coefficients[1]
lmA <- lm(y ~ -1 + x.centered, d, subset = d$g == "A", offset = d$offset)
lmB <- lm(y ~ -1 + x.centered, d, subset = d$g == "B", offset = d$offset)
plot(y ~ x.centered, d, pch = as.integer(d$g)^2, xlim = c(-5, 15),
     main = "x mean-centered", xlab = "x")
abline(lm, lty = 1)
abline(a = coef(lm)[1], b = coef(lmA), lty = 2)
abline(a = coef(lm)[1], b = coef(lmB), lty = 3)
@
\caption[Illustration for predictor mean-centering]{Illustration of
  the split point search without (left) und with (right) mean-centering
  the predictors. In this artificial scenario the slope of a predictor
  $x$ with $\bar{x}=10$ varies between two groups A (circles) and B
  (crosses). The solid lines show the slope of the global model and
  the dotted and dashed lines the group specific slopes of the search model with
  an intercept set equal to that of the global model.}
\label{fig:centering}
\end{figure}

The centering trick is applied by default, but can be disabled with
the control argument \code{center}. Note that the output model is not
affected by the mean-centering technique, because it is applied only
to the search model~$\widehat{\mathcal{M}}_{kmlj}$
(\ref{vcrpart-eq:alg-search}). Further, the trick is not
necessary when using the accurate search model
$\widehat{\mathcal{M}}^{*}_{kmlj}$ (\ref{vcrpart-eq:search}) that does not use the offset values.

\subsection{Additive expansion of multivariate varying coefficients}
\label{vcrpart-sec:contrasts}

An additional feature of TVCM is the possibility to avoid the interactions between moderators
by means of an additive expansion of varying coefficients. Although this
restriction may prevent the algorithm from finding the very best
model, coefficient functions with one moderator may be easier to
understand while still performing quite well as will be seen in
Section~\ref{vcrpart-sec:pima}.

\par

So far, we have implicitly assumed that the predictors $X_1, \ldots,
X_P$ of model~$\mathcal{M}_{\text{vc}}$ (\ref{vcrpart-eq:basic}) differ
from one another. To suppress interactions between moderators, we
expand the multivariate varying coefficients into additive,
moderator-wise components. First, consider a multivariate varying
coefficient term $x_{ip}\beta_p(\mathbf{z}_{ip}) =
x_{ip}\beta_p(z_{ip1}, \ldots, z_{ipL_{p}})$, possibly $x_{ip} = 1$
for all $i$. The additive expansion is

\begin{equation}
x_{ip}\beta(\mathbf{z}_{ip}) \enspace \longrightarrow \enspace x_{ip}\beta_{p0} +
x_{ip}\beta_{p1}(z_{ip1}) + \ldots + x_{ip}\beta_{ipL_{p}}(z_{ipL_p})\enspace.
\label{vcrpart-eq:additive-decomposition}
\end{equation}
Here, we decompose $x_{ip}\beta(\mathbf{z}_p)$ into the `isolated'
contributions of the individual moderators, including a global term
$x_{ip}\beta_{p0}$. In this expansion, the individual varying
coefficients $\beta_{pl}(z_{ipl})$, $l=1, \ldots, L_p$ act as local
contributions to the global coefficient $\beta_{p0}$. To identify the
additive expansion of Equation~\ref{vcrpart-eq:additive-decomposition}, we
mean-center the approximations for $\beta_{p1}(\cdot), \ldots,
\beta_{pL_{p}}(\cdot)$ using node-weighted sum contrasts that restrict
the sample-average of the coefficient functions to zero. That is, we
approximate $\beta_{pl}(\cdot)$ with the piecewise constant function
$\sum_{m=1}^{M_{pl}} 1(z_{ipl} \in \mathcal{B}_{plm}) \beta_{plm}$,
and estimate the coefficients $\beta_{pl1}, \ldots, \beta_{plM_{pl}}$
subject to

\begin{equation}
  \sum_{i=1}^N\sum_{m=1}^{M_{pl}} 1(z_{ipl} \in \mathcal{B}_{plm})
  w_i \beta_{plm} = 0\enspace.
\end{equation}
The nodewise-weighted sum contrasts are computed with the
\code{contr.wsum} function of \pkg{vcrpart}. We also considered
extending the additive expansion with second- and higher-order
interactions between moderators. However, such an extension likely
needs further considerations for the partitioning algorithm.

\subsection{Extension to other model classes}
\label{vcrpart-sec:extensions}

To extend the scope of the algorithm, the TVCM requires functions to
extract the training and validation errors from fitted models of the
considered model class. The training error is required for partitioning
(Algorithm~\ref{vcrpart-alg:partitioning}) and pruning
(Algorithm~\ref{alg:pruning}), and the need for extracting validation
errors arises from cross-validating $\lambda$. Both errors
refer to loss functions.
We suggest to use the loss function retained for estimating the coefficients, even though different functions could be specified in \pkg{vcrpart}.
%, which can (but are not obliged to) be the same as
%the one for estimating the coefficients.
For GLMs, we use as the
training error the total $-2\cdot\text{log-likelihood}$ loss on the
training sample, which can be extracted from the coefficient
estimation. Then, as the validation error, we use the average
$-2\cdot\text{log-likelihood}$ loss of predictions on validation sets,
which can be extracted using the \code{predict} and \code{family}
functions. Using the $-2\cdot\text{log-likelihood}$ loss for both
the training and validation errors synchronizes the criteria for
estimating the coefficients, selecting the split, pruning, and choosing
$\lambda$. The same, or similar implementation could be considered for
other likelihood-based regression models.

\par

The \pkg{vcrpart} package also provides implementations for the
baseline-category and the cumulative-link models to allow for
regression with nominal and ordinal responses. Both these models are
multivariate extensions of GLMs
\citep[cf.,][Chap.~3]{Fahrmeir2001}. Therefore, we can adopt the
definitions for the training and validation errors for GLMs \citep{BuerginRitschard2015CSDA}.


\section{Empirical evaluation}
\label{vcrpart-sec:evaluation}

Here, we present two empirical evaluations of the TVCM algorithm.
Section~\ref{vcrpart-sec:pima}
evaluates the performance of TVCM with different stopping criteria by comparing it with alternative tree-based algorithms on a benchmark data set.
Section~\ref{vcrpart-sec:simulation-study}
presents a simulation study to assess the ability of TVCM to identify
an underlying data generating varying coefficient process.

From here on and unless
specifically stated otherwise, the following default control parameters and
fixed seed for creating cross-validation folds will be used.

%TC:ignore
<<label = applications-control, echo = TRUE>>=

control <- tvcglm_control(folds = folds_control(seed = 13))
@
%TC:endignore


\subsection{Benchmarking TVCM with the Pima Indians diabetes data}
\label{vcrpart-sec:pima}

To evaluate the TVCM algorithm, we consider the Pima Indians diabetes
data of \cite{Smith1988}. These data are available from the UC Irvine
machine learning repository \citep{Bache2013} and record diabetes
tests of $768$ Pima Indian women, along with eight covariates. Here,
we use the \code{PimaIndiansDiabetes2}  data of the \proglang{R}
package \pkg{mlbench} \citep{Leisch2010} containing a version of the
original data corrected for physical impossibilities, such as zero
values for blood pressure. We exclude the two variables
\code{tricepts} and \code{insulin} and omit cases with missing values
of the remaining data by listwise deletion, which is also the default
option of \code{tvcglm}, to avoid expanding the discussion to the missing
value problem. The \code{Pima} data, prepared by the following
commands, include $\Sexpr{nrow(Pima)}$ observations on the seven
variables listed in Table~\ref{vcrpart-tab:pima}.%% \footnote{Descriptive
  %% statistics of these variables can be found in the
  %% Tables~\ref{vcrpart-appendix-tab:pima-nominal} and
  %% \ref{vcrpart-appendix-tab:pima-continuous}.}


%TC:ignore
<<label = pima-data>>=

library("mlbench")
data("PimaIndiansDiabetes2")
Pima <- na.omit(PimaIndiansDiabetes2[, -c(4, 5)])
@
%TC:endignore

\begin{table}[htbp]
  \centering\small
  \begin{tabular}{rllll}
    \hline
    & Variable & Label & Scale (Unit) & Range \\
    \hline
    1 & Diabetes & \code{diabetes} & Binary & Negative, Positive \\
    2 & Plasma glucose concentration & \code{glucose} & Continuous &
    $\left[44,199\right]$ \\
    3 & Number of times pregnant & \code{pregnant} & Continuous &
    $\left[0,17\right]$ \\
    4 & Diastolic blood pressure & \code{pressure} & Cont.
    ($mmHg$) &  $\left[24,122\right]$ \\
    5 & Body mass index & \code{mass} & Cont. ($kg/m^2$) &
    $\left[18.2,67.1\right]$ \\
    6 & Diabetes pedigree function & \code{pedigree} & Continuous &
    $\left[0.08,2.42\right]$ \\
    7 & Age & \code{age} & Cont. (years) & $\left[21,81\right]$ \\
    \hline
  \end{tabular}
  \normalsize
  \caption[\code{Pima} data: Variables]{Variables of the
    \code{Pima} data.}
  \label{vcrpart-tab:pima}
\end{table}

For this evaluation, we follow \cite{Zeileis2006} and model the
response variable \code{diabetes} using a logistic model with a varying
intercept and a varying slope for \code{glucose} in the predictor
function. The remaining covariates 3--7 of Table~\ref{vcrpart-tab:pima} are
used as potential moderators for both varying coefficients. The described model
is fitted with the command

%TC:ignore
<<label = pima-fitting-unconstrained, eval = FALSE>>=

vcm.Pima.1 <-
  tvcglm(diabetes ~ -1 + vc(pregnant, pressure, mass, pedigree, age) +
         vc(pregnant, pressure, mass, pedigree, age, by = glucose),
         data = Pima, family = binomial(), control = control)
@
%TC:endignore

where the first \code{vc} term specifies the varying intercept and the
second term specifies the varying slope for \code{glucose}. We use
`\code{-1}' to remove the global intercept so that the fitted varying
intercepts represent local intercepts. Keeping the global intercept
would produce the same fit. However, the fitted varying intercepts
would represent local contributions to the global intercept. The
alternative additive expansion introduced in
Section~\ref{vcrpart-sec:contrasts} is fitted using the command:

%TC:ignore
<<label = pima-fitting-additive, eval = FALSE>>=

vcm.Pima.2 <-
  tvcglm(diabetes ~ 1 + glucose +
         vc(pregnant) + vc(pregnant, by = glucose) +
         vc(pressure) + vc(pressure, by = glucose) +
         vc(mass) + vc(mass, by = glucose) +
         vc(pedigree) + vc(pedigree, by = glucose) +
         vc(age) + vc(age, by = glucose),
         data = Pima, family = binomial(), control = control)
@
%TC:endignore

The additive expansion includes a global intercept and a global slope
for \code{glucose}, which implies that the remaining varying
coefficients, which consist of moderator-wise varying intercepts and
varying slopes for \code{glucose}, represent local contributions.

\par

\cite{Zeileis2006} fit the same varying coefficient model using the
model-based recursive partitioning algorithm
\citep[MOB,][]{Zeileis2005}, which is based on the single-tree
approximation $\mathcal{M}_{\text{tree}}$
(\ref{vcrpart-eq:approx-1}). First, we compare the fit for
\code{vcm.Pima.1} with the fit based on MOB to discuss the structural
differences between the two approximations $\mathcal{M}_{\text{tree}}$
and $\mathcal{M}_{\text{tvcm}}$.

<<label = pima-fitting-mob, eval = FALSE, echo = FALSE>>=

## MOB-model fitted from 'glmtree' function
mob.Pima <-
    glmtree(diabetes ~ glucose | pregnant + pressure + mass +
                pedigree + age, data = Pima, family = binomial())

## construct same model with 'tvcglm' function
mob.Pima <-
    tvcglm(diabetes ~ -1 + vc(pregnant, pressure, mass, pedigree, age,
                              by = glucose, intercept = TRUE),
           data = Pima, family = binomial(),
           control = tvcglm_control(sctest = TRUE, cv = FALSE, maxnumsplit = 10000))
@

\begin{figure}[htbp]
  \centering
  \setkeys{Gin}{width=1\textwidth}

<<label = pima-fig-tree, fig = TRUE, echo = FALSE, width = 10, height = 5.75>>=

## plot the tvcm model
grid.newpage()
pushViewport(viewport(layout = grid.layout(1, 2, width = c(0.5, 0.5))))
pushViewport(viewport(layout.pos.col = 1))
grid.text("TVCM", y = unit(0.95, "npc"), gp = gpar(cex = 1.25))
pushViewport(viewport(
               y = unit(0.45, "npc"),
               width = unit(0.95, "npc"),
               height = unit(0.875, "npc")))
grid.rect()
pushViewport(viewport(height = unit(0.9, "npc"), y = unit(0.5, "npc")))
pushViewport(viewport(layout = grid.layout(1, 2, width = c(0.65, 0.35))))
pushViewport(viewport(layout.pos.col = 1))
plot(vcm.Pima.1, part = 1, type = "coef",
     newpage = FALSE)
grid.lines(unit(c(0.99, 0.99), "npc"),
           unit(c(0.05, 0.95), "npc"),
           gp = gpar(lty = 2, col = "black"))
upViewport(1)
pushViewport(viewport(layout.pos.col = 2))
plot(vcm.Pima.1, part = 2, type = "coef",
     plot_gp = list(width = 1), main = "vc(pregnant, ...,\n by = glucose)",
     newpage = FALSE)
upViewport(6)

## plot the MOB model
pushViewport(viewport(layout.pos.col = 2))
grid.text("MOB", y = unit(0.95, "npc"), gp = gpar(cex = 1.25))
pushViewport(viewport(
               y = unit(0.45, "npc"),
               width = unit(0.95, "npc"),
               height = unit(0.875, "npc")))
grid.rect()
plot(mob.Pima, newpage = FALSE, tnex = 4.5,
     main = "", margins = c(1.5, 0.75, 0, 0.75),
     parm = list("(Intercept)", "glucose"))
upViewport(2)
@
\caption[\code{Pima} data: Comparison between TVCM and MOB]{Fitted
  tree structures and nodewise coefficient plots. Left panel: The
  varying intercept (left) and the varying slope for
  \code{glucose} (right, no split) of the fit for
  \code{vcm.Pima.1}. Right panel: The fit based on MOB
  \citep[cf.,][]{Zeileis2006}.}
\label{fig:Pima-tree}
\end{figure}

\label{vcrpart-par:comparison-tree-plot}
The left panel in Figure~\ref{fig:Pima-tree} shows the fit for
\code{vcm.Pima.1} and the right panel the fit based on the MOB
algorithm. Note that the \pkg{partykit} plot function generates by default spinograms and not coefficient plots for the leaves of the MOB tree. For the sake of comparison, we have replaced here the default with coefficient plots.%
\footnote{The code for generating the plot with spinograms is given in the supplementary \proglang{R}-script.}
The structural difference with MOB is that
the TVCM fits separate  partitions for the varying intercept and the varying slope for
\code{glucose}, while MOB algorithm fits a common
partition for the two varying coefficients. Interestingly, the tree of
the varying intercept from the TVCM is identical to the tree from the
MOB algorithm. By contrast, the TVCM does not retain splits for the
slope of \code{glucose}. This illustrates the flexibility of the TVCM
in adapting to situations in which coefficient functions differ. If a
single partition for all varying coefficients is accurate, then the
TVCM can fit the same partition multiple times. Otherwise, it can
tailor the partition individually for each varying coefficient. As a
result, the TVCM potentially produces more parsimonious and/or more
accurate fits than does the $\mathcal{M}_{\text{tree}}$ approximation.

<<label = pima-comp-code, eval = TRUE, echo = FALSE>>=

## Comment:
## The following code runs the comparison study if
## 'run = TRUE' or the R data file 'vcrpart-bench' is
## not available.

run <- FALSE

if (run | !"vcrpart-bench.RData" %in% dir("RData/") ) {

    ## compute the missclassification error
    mce <- function(object, newdata) {
        if ("party" %in% class(object)) {
            mu <- predict(object, newdata = newdata, type = "response")
        } else if ("rpart" %in% class(object)){
            mu <- predict(object, newdata = newdata, type = "class")
        } else {
            mu <- predict(object, newdata = newdata)
        }
        mu <- if (is.factor(mu)) 1 * (mu == "pos") else round(mu)
        y <- 1 * (newdata$diabetes == "pos")
        return(sum(y != round(mu)) / nrow(newdata))
    }

    ## compute the complexity of the TVCM model
    npar.tvcm <- function(object) {
        return(extractAIC(extract(object, "model"))[1] +
                   sum(sapply(object$info$node, width) - 1))
    }

    ## Define formulas and control parameters
    ## --------------------------------------

    ## tvcm algorithm
    f1.tvcm <- f3.tvcm <- f4.tvcm <- f5.tvcm <-
        diabetes ~ -1 +
            vc(pregnant, pressure, mass, pedigree, age) +
                vc(pregnant, pressure, mass, pedigree, age, by = glucose)

    f2.tvcm <-
        diabetes ~ 1 + glucose +
            vc(pregnant) + vc(pregnant, by = glucose) +
                vc(pressure) + vc(pressure, by = glucose) +
                    vc(mass) + vc(mass, by = glucose) +
                        vc(pedigree) + vc(pedigree, by = glucose) +
                            vc(age) + vc(age, by = glucose)

    c1.Pima <- c2.Pima <-
        tvcm_control(papply.args = list(mc.cores = 6),
                     folds = folds_control(seed = 13))
    c3.Pima <-
        tvcm_control(minsize = 50,
                     papply.args = list(mc.cores = 6),
                     folds = folds_control(seed = 13))
    c4.Pima <-
        tvcm_control(mindev = 50,
                     papply.args = list(mc.cores = 6),
                     folds = folds_control(seed = 13))
    c5.Pima <-
        tvcm_control(papply.args = list(mc.cores = 6),
                     folds = folds_control(seed = 13),
                     maxnumsplit = 19)

    ## MOB algorithm
    f.MOB <- diabetes ~ glucose | pregnant + pressure + mass + pedigree + age

                                        # rpart and other algorithms
    f.rpart <- diabetes ~ pregnant + glucose + pressure +  mass + pedigree + age


    ## Fit models on all data
    ## ----------------------

    algs <- c("TVCM1", "TVCM2", "TVCM3", "TVCM4", "TVCM5",
              "MOB", "CTree", "CART", "LMT", "J4.8")

    e.is <- c.is <- t.is <- rep(NA, length(algs))
    names(e.is) <- names(c.is) <- names(t.is) <- algs

    cat("\n * fitting the model to all data ... ")

    ## TVCM algorithm
    ptm <- proc.time()
    tvcm.Pima <- tvcm(f1.tvcm, data = Pima, family = binomial(), control = c1.Pima)
    t.is["TVCM1"] <- (proc.time() - ptm)[3]
    e.is["TVCM1"] <- mce(tvcm.Pima, Pima)
    c.is["TVCM1"] <- npar.tvcm(tvcm.Pima)

    ptm <- proc.time()
    tvcm.Pima <- tvcm(f2.tvcm, data = Pima, family = binomial(), control = c1.Pima)
    t.is["TVCM2"] <- (proc.time() - ptm)[3]
    e.is["TVCM2"] <- mce(tvcm.Pima, Pima)
    c.is["TVCM2"] <- npar.tvcm(tvcm.Pima)

    ptm <- proc.time()
    tvcm.Pima <- tvcm(f3.tvcm, data = Pima, family = binomial(), control = c3.Pima)
    t.is["TVCM3"] <- (proc.time() - ptm)[3]
    e.is["TVCM3"] <- mce(tvcm.Pima, Pima)
    c.is["TVCM3"] <- npar.tvcm(tvcm.Pima)

    ptm <- proc.time()
    tvcm.Pima <- tvcm(f4.tvcm, data = Pima, family = binomial(), control = c4.Pima)
    t.is["TVCM4"] <- (proc.time() - ptm)[3]
    e.is["TVCM4"] <- mce(tvcm.Pima, Pima)
    c.is["TVCM4"] <- npar.tvcm(tvcm.Pima)

    ptm <- proc.time()
    tvcm.Pima <- tvcm(f5.tvcm, data = Pima, family = binomial(), control = c5.Pima)
    t.is["TVCM5"] <- (proc.time() - ptm)[3]
    e.is["TVCM5"] <- mce(tvcm.Pima, Pima)
    c.is["TVCM5"] <- npar.tvcm(tvcm.Pima)

    ## MOB algorithm
    ptm <- proc.time()
    MOB.Pima <- glmtree(formula = f.MOB, data = Pima, family = binomial)
    t.is["MOB"] <- (proc.time() - ptm)[3]
    e.is["MOB"] <- mce(MOB.Pima, Pima)
    c.is["MOB"] <- 3 * width(MOB.Pima) - 1

    ## CTree algorithm
    ptm <- proc.time()
    CTree.Pima <- ctree(formula = f.rpart, data = Pima)
    t.is["CTree"] <- (proc.time() - ptm)[3]
    e.is["CTree"] <- mce(CTree.Pima, Pima)
    c.is["CTree"] <- 2 * width(CTree.Pima) - 1

    ## CART algorithm
    ptm <- proc.time()
    rpart.Pima <- rpart(formula = f.rpart, data = Pima)
    cp.rpart <- rpart.Pima$cptable[which.min(rpart.Pima$cptable[,"xerror"]),"CP"]
    rpart.Pima <- prune(rpart.Pima, cp = cp.rpart)
    t.is["CART"] <- (proc.time() - ptm)[3]
    e.is["CART"] <- mce(rpart.Pima, Pima)
    c.is["CART"] <- 2 * length(unique(rpart.Pima$where)) - 1

    require("RWeka")
    ## LMT algorithm
    ptm <- proc.time()
    LMT.Pima <- LMT(formula = f.rpart, data = Pima)
    t.is["LMT"] <- (proc.time() - ptm)[3]
    e.is["LMT"] <- mce(LMT.Pima, Pima)
    c.is["LMT"] <- 2 * width(as.party(LMT.Pima)) - 1

    ## J4.8 algorithm
    ptm <- proc.time()
    J48.Pima <- J48(formula = f.rpart, data = Pima)
    t.is["J4.8"] <- (proc.time() - ptm)[3]
    e.is["J4.8"] <- mce(J48.Pima, Pima)
    c.is["J4.8"] <- 2 * width(as.party(J48.Pima)) - 1

    cat("OK")

    ## Performance test
    ## ----------------

    cat("\n * starting performance test ... ")

    nsim <- 250
    folds <- folds_control(type = "bootstrap", K = nsim, seed = 123)
    folds <- vcrpart:::tvcm_folds(tvcm.Pima, folds)
    dn <- list(1:nsim, algs)
    e.boot <- c.boot <- t.boot <- matrix(, nsim, length(algs), dimnames = dn)

    rm(tvcm.Pima, MOB.Pima, CTree.Pima, rpart.Pima, LMT.Pima, J48.Pima)

    for (i in 1:nsim) {
        cat("\n\tfold", i, "... ")

        ## extract training data
        subs <- rep(1:nrow(Pima), folds[, i])
        training <- Pima[subs, ]

        ## extract validation data
        subs <- folds[,i] == 0
        validation <- Pima[subs, ]

        c1.Pima$folds$seed <- i
        c3.Pima$folds$seed <- i
        c4.Pima$folds$seed <- i
        c5.Pima$folds$seed <- i

        ## tvcm algorithm
        ptm <- proc.time()
        tvcmB.Pima <-
            try(tvcm(f1.tvcm, data = training, family = binomial(),
                     control = c1.Pima),
                silent = TRUE)
        if (!inherits(tvcmB.Pima, "try-error")) {
            t.boot[i, "TVCM1"] <- (proc.time() - ptm)[3]
            e.boot[i, "TVCM1"] <- mce(tvcmB.Pima, validation)
            c.boot[i, "TVCM1"] <- npar.tvcm(tvcmB.Pima)
        }

        ptm <- proc.time()
        tvcmB.Pima <-
            try(tvcm(f2.tvcm, data = training, family = binomial(),
                     control = c2.Pima),
                silent = TRUE)
        if (!inherits(tvcmB.Pima, "try-error")) {
            t.boot[i, "TVCM2"] <- (proc.time() - ptm)[3]
            e.boot[i, "TVCM2"] <- mce(tvcmB.Pima, validation)
            c.boot[i, "TVCM2"] <- npar.tvcm(tvcmB.Pima)
        }

        ptm <- proc.time()
        tvcmB.Pima <-
            try(tvcm(f1.tvcm, data = training, family = binomial(),
                     control = c3.Pima),
                silent = TRUE)
        if (!inherits(tvcmB.Pima, "try-error")) {
            t.boot[i, "TVCM3"] <- (proc.time() - ptm)[3]
            e.boot[i, "TVCM3"] <- mce(tvcmB.Pima, validation)
            c.boot[i, "TVCM3"] <- npar.tvcm(tvcmB.Pima)
        }

        ptm <- proc.time()
        tvcmB.Pima <-
            try(tvcm(f1.tvcm, data = training, family = binomial(),
                     control = c4.Pima),
                silent = TRUE)
        if (!inherits(tvcmB.Pima, "try-error")) {
            t.boot[i, "TVCM4"] <- (proc.time() - ptm)[3]
            e.boot[i, "TVCM4"] <- mce(tvcmB.Pima, validation)
            c.boot[i, "TVCM4"] <- npar.tvcm(tvcmB.Pima)
        }

        ptm <- proc.time()
        tvcmB.Pima <-
            try(tvcm(f1.tvcm, data = training, family = binomial(),
                     control = c5.Pima),
                silent = TRUE)
        if (!inherits(tvcmB.Pima, "try-error")) {
            t.boot[i, "TVCM5"] <- (proc.time() - ptm)[3]
            e.boot[i, "TVCM5"] <- mce(tvcmB.Pima, validation)
            c.boot[i, "TVCM5"] <- npar.tvcm(tvcmB.Pima)
        }

        ## MOB algorithm
        ptm <- proc.time()
        MOBB.Pima <- try(glmtree(formula = f.MOB, data = training,
                                 family = binomial),
                         silent = TRUE)
        t.boot[i, "MOB"] <- (proc.time() - ptm)[3]
        e.boot[i, "MOB"] <- mce(MOBB.Pima, validation)
        c.boot[i, "MOB"] <- 3 * width(MOBB.Pima) - 1

        ## CTree algorithm
        ptm <- proc.time()
        CTreeB.Pima <- try(ctree(formula = f.rpart, data = training), silent = TRUE)
        if (!inherits(CTreeB.Pima, "try-error")) {
            t.boot[i, "CTree"] <- (proc.time() - ptm)[3]
            e.boot[i, "CTree"] <- mce(CTreeB.Pima, validation)
            c.boot[i, "CTree"] <- 2 * width(CTreeB.Pima) - 1
        }

        ## CART algorithm
        ptm <- proc.time()
        rpartB.Pima <- try(rpart(formula = f.rpart, data = training), silent = TRUE)
        if (!inherits(rpartB.Pima, "try-error")) {
            cpB.Pima <-
                rpartB.Pima$cptable[which.min(rpartB.Pima$cptable[,"xerror"]),"CP"]
            rpartB.Pima <- prune(rpartB.Pima, cp = cpB.Pima)
            t.boot[i, "CART"] <- (proc.time() - ptm)[3]
            e.boot[i, "CART"] <- mce(rpartB.Pima, validation)
            c.boot[i, "CART"] <- 2 * length(unique(rpartB.Pima$where)) - 1
        }

        ## LMT algorithm
        ptm <- proc.time()
        LMTB.Pima <- try(LMT(formula = f.rpart, data = training), silent = TRUE)
        if (!inherits(LMTB.Pima, "try-error")) {
            t.boot[i, "LMT"] <- (proc.time() - ptm)[3]
            e.boot[i, "LMT"] <- mce(LMTB.Pima, validation)
            c.boot[i, "LMT"] <- 2 * width(as.party(LMTB.Pima)) - 1
        }

        ## J4.8 algorithm
        ptm <- proc.time()
        J48B.Pima <- try(J48(formula = f.rpart, data = training), silent = TRUE)
        if (!inherits(J48B.Pima, "try-error")) {
            t.boot[i, "J4.8"] <- (proc.time() - ptm)[3]
            e.boot[i, "J4.8"] <- mce(J48B.Pima, validation)
            c.boot[i, "J4.8"] <- 2 * width(as.party(J48B.Pima)) - 1
        }

        rm(tvcmB.Pima, MOBB.Pima, CTreeB.Pima, rpartB.Pima, LMTB.Pima, J48B.Pima)

        gc(verbose = FALSE)

        cat("OK")
    }

    rm(f1.tvcm, f2.tvcm, f.MOB, f.rpart,
       c1.Pima, c2.Pima, c3.Pima, c4.Pima, c5.Pima,
       ptm, dn)

    save(algs, folds, nsim,
         t.is, e.is, c.is,
         t.boot, e.boot, c.boot,
         file = "RData/vcrpart-bench.RData")
} else {

    load(file = "RData/vcrpart-bench.RData")

}

@

<<label = pima-MOB-spinogram, echo = FALSE, eval = FALSE>>=

## original plot of MOB model
f.MOB <- diabetes ~ glucose | pregnant + pressure + mass + pedigree + age
MOB.Pima <- glmtree(formula = f.MOB, data = Pima, family = binomial)
plot(MOB.Pima)
@

\paragraph{Comparison with competing tree-based algorithms} To
evaluate the performance of the TVCM, we extend the
benchmark study of \cite{Zeileis2006} who, using the same
\code{Pima} data, compare MOB with the conditional inference
  tree \citep[CTree,][]{Hothorn2006}, CART \citep{Breiman1984},
the logistic model tree \citep[LMT,][]{Landwehr2005}, and C4.5
\citep{Quinlan1993} algorithms.%
\footnote{Here, we do not consider the quick, unbiased, efficient,
statistical tree algorithm \citep[QUEST][]{Loh1997} included in the
study by \cite{Zeileis2006}.}
The MOB and CTree algorithms
are implemented in the \proglang{R} \pkg{partykit} package
\citep{Hothorn2014} (and \pkg{party}), CART in \pkg{rpart}
\citep{Therneau2014}, and LMT and C4.5 in \pkg{RWeka}
\citep{Hornik2009}. We denote CART as RPART and C4.5 as J4.8 because
the corresponding \proglang{R} implementations are slightly modified versions.

\par

\label{rep-250-bootstrap}
The performance comparison is made with the \code{Pima} data and
relies on 250 bootstrap samples with
replacement (as in~\citealt{Zeileis2006}). For each bootstrap sample, we
fit a model with each algorithm to predict the excluded
observations. In the case of the TVCM, we fit five models on each bootstrap
sample to compare the fits for \code{tvcm.Pima.1} and \code{tvcm.Pima.2}
and to evaluate the sensitivity of fits for \code{tvcm.Pima.1} to
changes from the defaults for $N_0$ (the minimum node size), $D_{min}$
(the minimum training error reduction), and $N_S$ (the maximum number
of splits). For the competitors, we employ the default control
parameters. Three comparison  measures are considered:
Misclassification, the median and mean 0-1 loss on excluded data;
complexity, the median of the number of coefficients plus the
number of splits; and time, the median computation
time. Furthermore, with each algorithm, we fit a model on the original
data. To run the simulation, we use a computer with an Intel Xeon
3.50GHz processor.

<<label = pima-table-comp, echo = FALSE, results = tex>>=

subs <- intersect(1:250, which(!is.na(e.boot[,1])))
e.boot <- e.boot[subs, ]
c.boot <- c.boot[subs, ]
t.boot <- t.boot[subs, ]
tab.Pima <- data.frame("Boot" = apply(e.boot, 2, median, na.rm = TRUE),
                       "Boot-Mean" = apply(e.boot, 2, mean, na.rm = TRUE),
                       "Orig" = e.is,
                       "Boot" = apply(c.boot, 2, median, na.rm = TRUE),
                       "Orig" = c.is,
                       "Boot" = apply(t.boot, 2, median, na.rm = TRUE),
                       "Orig" = t.is,
                       check.names = FALSE)
cap <- c("Performances for the \\code{Pima} data. Boot: Medians (and means under Boot-Mean) of results from fits on 250 bootstrap samples. Orig: Results on the original data. Misclassification: Misclassification errors. Complexity: The number of coefficients plus the number of splits. Time: Computation time in seconds.", "Performances for the \\code{Pima} data")
algs2 <- algs
algs2[1:5] <- c("TVCM (default)",
                "TVCM (additive)",
                "TVCM ($N_0 = 50$)",
                "TVCM ($D_{min} = 50$)",
                "TVCM ($N_S = 19$)")
algs2[8L] <- "RPART"
rownames(tab.Pima) <- algs2
rownames(tab.Pima)[1L] <- "TVCM"
xtab.Pima <- xtable(x = tab.Pima,
                    caption = cap,
                    label = "vcrpart-tab:pima-performance",
                    align = "lrrr|rr|rr",
                    digits = c(0, 3, 3, 3, 0, 0, 2, 2),
                    display = c("s", "f", "f", "f", "d", "d", "f", "f"))
addtorow <- list(pos = list(-1),
                 command = "\\hline & \\multicolumn{3}{c}{Misclassification} & \\multicolumn{2}{c}{Complexity} & \\multicolumn{2}{c}{Time} \\\\")
print(x = xtab.Pima,
      table.placement = "tbp",
      caption.placement = "bottom",
      latex.environments = "center",
      sanitize.text.function = function(x) x,
      booktabs = FALSE,
      hline.after = c(0, nrow(xtab.Pima)),
      add.to.row = addtorow, size="\\small")
@

\label{vcrpart-par:comparison-table}
Table~\ref{vcrpart-tab:pima-performance} shows that the TVCM
outperforms the competitors in terms of performance and
complexity. That is, it builds smaller models with slightly
better predictive performance than the other algorithms. By contrast, the
TVCM performs worst in terms of computational time because it
evaluates far more candidate models than do the
competitors. Increasing $N_0$ and $D_{min}$ accelerates the burden
significantly, with surprisingly little effect on the
performance. Apparently, in this application, it is not necessary to
grow very large trees in the partitioning stage to produce an accurate
fit. Furthermore, the difference between the multivariate varying
coefficient specification and the additive expansion is negligibly
small in this application.

\begin{figure}[htbp]
  \centering
  \setkeys{Gin}{width=1\textwidth}

<<label = pima-fig-comp, fig = TRUE, echo = FALSE, width = 10, height = 4.25>>=

nsim <- length(subs)
algs3 <- algs
algs3[2] <- expression(paste("TVCM (additive)", sep = ""))
algs3[3] <- expression(paste("TVCM (", N[0], "= 50)", sep = ""))
algs3[4] <- expression(paste("TVCM (", D[min], "= 50)", sep = ""))
algs3[5] <- expression(paste("TVCM (", N[S], " = 19)", sep = ""))
algs3[8] <- "RPART"
par(mfrow = c(1,2), mgp = c(2.25, 1, 0), mar = c(3.5, 8, 0.5, 2))
e.boot.long <-
  data.frame(MCE = c(e.boot),
             ALG = factor(rep(algs, each = nsim), levels = algs))
mod <- lm(MCE ~ ALG, e.boot.long)
ci <- confint(mod)
plot(coef(mod)[-1], length(coef(mod)[-1]):1, pch = 16,
     xlim = c(-0.01, 0.045), axes = FALSE, ylab = "",
     xlab = "Misclassification difference")
axis(1); axis(2, length(coef(mod)[-1]):1, algs3[-1], las = 2); box();
abline(v = 0, lty = 2)
arrows(ci[-1,1], length(coef(mod)[-1]):1,
       ci[-1,2], length(coef(mod)[-1]):1, angle = 90, code = 3, length = 0.075)
c.boot.long <-
  data.frame(DF = c(c.boot),
             ALG = factor(rep(algs, each = nsim), levels = algs))
mod <- lm(DF ~ ALG, c.boot.long)
ci <- confint(mod)
plot(coef(mod)[-1], length(coef(mod)[-1]):1,
     axes = FALSE, ylab = "", pch = 16,
     xlab = "Complexity difference", xlim = c(-12,80))
axis(1); axis(2, length(coef(mod)[-1]):1, algs3[-1], las = 2); box();
abline(v = 0, lty = 2)
arrows(ci[-1,1], length(coef(mod)[-1]):1, ci[-1,2], length(coef(mod)[-1]):1,
       angle = 90, code = 3, length = 0.075)
@
\caption[Performances for the \code{Pima} data relative to
TVCM]{Performances for the \code{Pima} data relative to TVCM with default
  control parameters. Left panel: Average differences in
  misclassification errors. Right panel: Average differences in complexity.}
\label{fig:pima-performance}
\end{figure}

Figure~\ref{fig:pima-performance} shows averages of 250 pairwise
differences between the competitors and the TVCM. The confidence
intervals for the averages are based on the Student's
t-distribution. Several average differences are significant in favor
of the TVCM. It may be that the CTree, RPART, LMT, and J4.8
algorithms perform worse because they merely use piecewise constant
regression functions, whereas the TVCM and the MOB algorithm include a
(prespecified) slope for \code{glucose}.

\subsection{Simulation study}
\label{vcrpart-sec:simulation-study}

<<label=vcrpart-simulations-code, eval = TRUE, echo = FALSE>>=

## Comment:
## The following code runs the simulation study if
## 'run = TRUE' or the R data file 'RData/vcrpart-simulations.RData' is
## not available.


run <- FALSE

## function to generate the data
generate.data <- function(N = 200) {
    rval <- data.frame(x = rnorm(N),
                       z0 = rbinom(N, 1, 0.5),
                       z1 = rbinom(N, 1, 0.5),
                       z2 = rbinom(N, 1, 0.5),
                       z3 = rbinom(N, 1, 0.5),
                       z4 = rbinom(N, 1, 0.5),
                       z5 = rbinom(N, 1, 0.5))
    rval$group <- factor(paste(rval$z0,rval$z1, sep = "-"))
    levels(rval$group) <- c("1", "1", "2", "3")
    rval$y1 <- model.matrix(~ z0 + x + z1:x, rval) %*% c(-1, 2, 1, -1) +
        rnorm(N)
    return(rval)
}

## function that executes a single simulation run
simFun <- function(N = 100) {
    cat(".")
    rval <- matrix(FALSE, 2, 4)
    z <- c("z0", "z1", "z2", "z3", "z4", "z5")

    ## set control according to sample size
    control.sim <- tvcglm_control(apply.args = list(mc.cores = 6),
                                  mindev = min(N / 200, 2),
                                  minsize = min(N / 20, 30))

    ## generate data
    dat <- generate.data(N = N)

    ## fit the models
    m1 <- tvcglm(y1 ~ - 1 + vc(z) + vc(z, by = x),
                 family = gaussian(), data = dat,
                 control = control.sim)
    m2 <- tvcglm(y1 ~ - 1 + vc(z, by = x, intercept = TRUE),
                     family = gaussian(), data = dat,
                 control = control.sim)

    n1 <- extract(m1, "nodes")
    n2 <- extract(m2, "nodes")

    ## check whether the algorithms found true structure
    rval[1,1] <-
        (width(n1$A) == 2 &&
             unlist(nodeapply(n1$A, 1, function(x) x$split$varid)) == 1) &
                 (width(n1$B) == 2 &&
                      unlist(nodeapply(n1$B, 1, function(x) x$split$varid)) == 2)
    rval[2,1] <-
        width(n2$A) == 4 &&
            (all(unlist(nodeapply(n2$A, c(1,2,5),
                                  function(x) x$split$varid)) %in% c(1,2,2)) |
                                      all(unlist(nodeapply(n2$A, c(1,2,5),
                                                           function(x) x$split$varid)) %in% c(2,1,1)))

    ## check whether the fits include the true structure as a nested model
    rval[1,2] <-
        (width(n1$A) > 1 &&
             unlist(nodeapply(n1$A, 1, function(x) x$split$varid)) == 1) &
                (width(n1$B) > 1 &&
                     unlist(nodeapply(n1$B, 1, function(x) x$split$varid)) == 2)
    rval[2,2] <-
        width(n2$A) >= 4 &&
            (all(unlist(nodeapply(n2$A, c(1,2,5),
                                  function(x) x$split$varid)) %in% c(1,2,2)) |
                                      all(unlist(nodeapply(n2$A, c(1,2,5),
                                                           function(x) x$split$varid)) %in% c(2,1,1)))

    ## check whether true effect modifiers were chose
    rval[1,3] <- "z0" %in% extract(m1, "selected")[[1]] &
        "z1" %in% extract(m1, "selected")[[2]]
    rval[2,3] <- all(c("z0", "z1") %in% extract(m2, "selected")[[1]])

    ## check whether noise variables were chosen
    rval[1,4] <- sum(!unique(unlist(extract(m1, "selected"))) %in% c("z0", "z1"))
    rval[2,4] <- sum(!unique(unlist(extract(m2, "selected"))) %in% c("z0", "z1"))

    return(c(rval))
}

if (run | !"vcrpart-simulations.RData" %in% dir("RData/")) {
    nsim <- 2000 # the number of simulation runs
    N <- c(50, 100, 150, 200, 250, 300, 350, 400, 450, 500)
    par <- rep(N, each = nsim)
    res <- mclapply(X = par, simFun, mc.cores = 1)
    save(res, par, N, nsim, file = "RData/vcrpart-simulations.RData")
} else {
    load(file = "RData/vcrpart-simulations.RData")
}


@

Here, we use simulated data to evaluate the ability of TVCM to identify an
underlying data generating process with coefficients varying across
coefficient-wise partitions. In particular, we consider a scenario where the
varying coefficients of the data generating model depend on different
moderator variables, in which case we would expect coefficient-wise
partitioning to perform better than a single partitioning approach.

\par

The study consists in generating multiple datasets by means of a simulation model,
and fitting a model with the coefficient-wise and a model with the single
partitioning approach on each of the datasets. The two approaches are
then compared by means of four performance measures.
%
For each dataset, we draw $N$ realizations of a
normally distributed predictor variable $X \stackrel{i.i.d.}{\sim}
\mathcal{N}(0,1)$, and $N$ realizations of each of 6 independent
Bernoulli moderator variables $Z_0, \ldots, Z_{5}$ with
$Z_{l} \stackrel{i.i.d.}{\sim} \text{Bin}(1,0.5)$. Using these data,
we draw $N$ responses $y_1, \ldots, y_N$ from the simulation
model:

\begin{equation}
  \mathcal{M}_{\text{sim}}: y_i = \left[-1 +
  2 \cdot 1_{(z_{0i} > 0)} \right]+
  \left[ 1 - 2 \cdot 1_{(z_{1i} > 0)} \right] \cdot x_i  + \varepsilon_i,
  \quad \varepsilon_i \stackrel{i.i.d.}{\sim} \mathcal{N}(0, 1)
  \label{eq:model-sim}
\end{equation}

The model $\mathcal{M}_{\text{sim}}$ (\ref{eq:model-sim}) has
a varying intercept that depends on $Z_0$, and a varying slope for $X$ that depends on
$Z_1$. The additional four variables $X_2$ to $X_5$ act as noise variables that
we expect to not be selected. Since both the varying intercept and the varying slope are
threshold functions, they can be reconstructed by recursive
partitioning. Coefficient-wise partitioning can reconstruct the model
with two splits, a first split for the varying intercept in $Z_0$ and
a second split for the varying slope for $X$ in $Z_1$. The single
partition approach needs to perform three splits. Either, it splits
the root node by $Z_0$ and both child nodes by $Z_1$, or it splits the
root node by $Z_1$ and both child nodes by $Z_1$. The sample size $N$
is varied by steps of 50 between 50 and 500, and 2000 runs are made for
each $N$, which makes a total of 20,000 simulated datasets.

\par

Both the model with coefficient-wise partitions and the model with a
single partition are fitted with the \code{tvcglm} function. Using
for both models \code{tvcglm} allows to isolate the comparison between
the coefficient-wise and single partition approaches from
other differences between the algorithms. For example, \code{glmtree}
could be used to fit the single partition model, but then the
performance differences would also relate to implementation-specific
differences between
TVCM and MOB such as the splitting criterion. Apart from computational
details, the procedure used by \code{tvcglm} to fit single partition models
is equivalent to that of \cite{Wang2013}. Here are the
\proglang{R}-commands used to fit the two models, where the data frame
\code{simdata} presents a placeholder for a generated dataset.

<<label=vcrpart-simulations-arbitrarydata, echo = FALSE, eval = FALSE>>=

## generate an arbitrary simulation data set with 100 observations
N <- 100
simdata <- generate.data(N = N)
simdata$y <- simdata$y1
@

<<label=vcrpart-simulations-moderators, eval = FALSE>>=

z <- c("z0", "z1", "z2", "z3", "z4", "z5")
control.sim <-
    tvcglm_control(mindev = min(N / 200, 2), minsize = min(N / 20, 30))
@

<<label=vcrpart-simulations-models-1, eval = FALSE>>=

vcm.sim.1 <- # coefficient-wise partitions model
    tvcglm(y ~ -1 + vc(z) + vc(z, by = x), data = simdata,
           family = gaussian(), control = control.sim)
@
<<label=vcrpart-simulations-models-2, eval = FALSE>>=

vcm.sim.2 <- # single partition model
    tvcglm(y ~ -1 + vc(z, by = x, intercept = TRUE),
           data = simdata, family = gaussian(), control = control.sim)
@
As can be seen from
the code for \code{vcm.sim.2}, a single \code{vc} term in the
formula with the arguments `\code{intercept = TRUE}'  and `\code{by = x}'
allows to fit a common partition for the varying intercept and the
slope for $X$. The minimum node size $N_0$ and the minimum training
error reduction $D_{min}$ arguments
(cf., Algorithm~\ref{vcrpart-alg:partitioning}) are specified such that
identifying the true model and selecting noise variable remains possible
for small sample sizes. For this purpose---to some extent arbitrarily
chosen---truncated linear functions are used. For $N=200$ for example,
the retained functions set the minimum node size (\code{minsize})
as $N_0=10$ and the minimum required deviance improvement
(\code{mindev}) as  $D_{min}=1$.

\paragraph{Performance measures} To evaluate the fitted models, four
frequency measures are considered: (i) Identified underlying model, the
proportion of runs for which the exact underlying model was identified; (ii)
nested underlying model, the proportion of runs for which the underlying
model is nested in the fitted model; (iii) true
moderators selected, the proportion of runs for which all true moderators
were selected; and (iv) false variable selections, the proportion of
runs that selected noise moderators.

\begin{figure}[bt]
  \centering
  \setkeys{Gin}{width=1\textwidth}
<<label = pima-fig-simulations, echo = FALSE, fig = TRUE, width = 7.5, height = 2.75>>=

res <- sapply(res, I)
res <- apply(res, 1, function(x) tapply(x, par, function(x) sum(x) / length(x)))

par(mfrow = c(1, 4), mgp = c(2, 1, 0), mar = c(3, 3, 3, 1))
matplot(x = N, y = res[, 1:2], type = "b", col = "black",
        ylab = "Proportion of runs", ylim = c(0, 1),
        main = "Identified\n underlying model",
        pch = 1:2, xlab = "Number of observations")
abline(h = c(0, 1), lty = 3)
matplot(x = N, y = res[, 3:4], type = "b", col = "black",
        ylab = "Proportion of runs",
        ylim = c(0, 1), main = "Nested\n underlying model",
        pch = 1:2, xlab = "Number of observations")
abline(h = c(0, 1), lty = 3)
matplot(x = N, y = res[, 5:6], type = "b", col = "black",
        ylab = "Proportion of runs",
        ylim = c(0, 1), main = "True moderators\n selected",
        pch = 1:2, xlab = "number of observations")
abline(h = c(0, 1), lty = 3)
matplot(x = N, y = res[, 7:8], type = "b", col = "black",
        ylab = "Proportion of runs",
        ylim = c(0, 1), main = "False\n variable selections",
        pch = 1:2, xlab = "Number of observations")

@
\caption[Performance simulation study]{Performance comparison of
  coefficient-wise partitioning (solid lines) and single
  partitioning (dashed lines). }
\label{fig:Pima-simulations}
\end{figure}

\paragraph{Results} Figure~\ref{fig:Pima-simulations} contrasts the
performances of coefficient-wise partitioning to the single partition
approach. All four measures tend to a same asymptote for both approaches
with, however, a faster convergence for the coefficient-wise partitioning.
For our generated data, the chances to identify the exact generating model
tends to about 85\% when the sample size $N$ becomes large ($N\geq 150$ for
coefficient-wise partitioning and $N\geq 300$ for single partitioning),
while the chances to end up with a model that includes the generating process
as a nested model tends to 1. This shows that the presence of the noise
variables leads in some cases to overfitting. Similar conclusions hold
for the two other indicators: When $N$ becomes large both approaches
select at least all true moderators together with, in 20\% of the cases, some
noise variables. In sum, the above simulation study indicates that
coefficient-wise partitioning is better than single partitioning in retrieving
the exact generating process with a sample of moderated size $N$, while both approaches
look equivalent when $N$ becomes large ($\geq 350$). It also shows that,
when $N\geq 200$, the methods tend to select a set of moderators that include at
least all true moderators.

\section{Applications}
\label{vcrpart-sec:applications}

We now illustrate the usage of the \pkg{vcrpart} library to tackle
moderated regression problems in social science research. Two applications
are presented. We demonstrate the general multivariate varying coefficient
specification in Section~\ref{vcrpart-sec:race} and the additive
expansion in Section~\ref{vcrpart-sec:PL}.
%A performance comparison
%between the two specifications is provided in
%Section~\ref{vcrpart-sec:pima}.



\subsection{The racial wage gap}
\label{vcrpart-sec:race}

The first application is a study of the racial wage gap and, more
specifically, a study of whether the wage gap varies across strata.
A suitable data set to examine the issue is the \code{Schooling} data of the
\proglang{R} package \pkg{Ecdat} \citep{Croissant2014}. The
\code{Schooling} data are a cross-section of
$\Sexpr{format(nrow(Schooling), big.mark = ",")}$ men prepared by
\cite{Card1993} from the 1976 wave of the US National Longitudinal
Survey of Young Men (NLSYM).%
\footnote{See
  \url{http://davidcard.berkeley.edu/data_sets.html}.}
Table~\ref{vcrpart-tab:tab-earnings} describes the variables of the
\code{Schooling} data, where \code{lwage76} is the response
variable and the dummy \code{black}  the predictor of
interest.%% \footnote{Descriptive statistics of these
  %% variables can be found in the
  %% Tables~\ref{vcrpart-appendix-tab:school-nominal} and
  %% \ref{vcrpart-appendix-tab:school-continuous}.}
The data were prepared as follows.

%TC:ignore
<<label = school-data, eval = TRUE, echo = TRUE>>=

library("Ecdat")
data("Schooling")
Schooling <- Schooling[c(19, 21, 7, 28, 9, 14, 17, 18, 20, 23, 2, 4)]
Schooling$black <- 1 * (Schooling$black == "yes")
@
%TC:endignore

\begin{table}[btp]
  \centering
  \small
  \begin{tabular}{rllll}
    \hline
    & Variable & Label & Scale (Unit) & Values \\
    \hline
    1 & Logarithm wage per hour 1976 & \code{lwage76} &
    Cont. (\textcent/h) & $\left[4.6,9\right]$ \\
    2 & Is person black? & \code{black} & Binary & 0=No, 1=Yes \\
    3 & Education in 1976 & \code{ed76} & Continuous &
    $\left[1,18\right]$ \\
    4 & Working experience in 1976 & \code{exp76} & Continuous &
    $\left[0,23\right]$ \\
    5 & Age in 1976 & \code{age76} & Cont. (years) &
    $\left[24,34\right]$ \\
    6 & Lived with mom/ dad at age 14? & \code{momdad14} &
    Binary & No, Yes \\
    7 & Lived in south in 1966? & \code{south66} & Binary & No, Yes \\
    8 & Lived in south in 1976? & \code{south76} & Binary & No, Yes \\
    9 & Mother-father education class & \code{famed} & Continuous &
    $\left[1,9\right]$ \\
    10 & Enrolled in 1976? & \code{enroll76} & Binary & No, Yes \\
    11 & Lived in smsa in 1976? & \code{smsa76} & Binary & No, Yes \\
    12 & Grew up near 4-yr college? & \code{nearc4} & Binary & No, Yes \\
    \hline
  \end{tabular}
  \normalsize
  \caption[\code{Schooling} data: Variables]{The subset of used
    variables of the \code{Schooling} data.}
  \label{vcrpart-tab:tab-earnings}
\end{table}

A standard model for wage is provided by the Mincer equation
\citep{Mincer1974}, stating that schooling and working experience are
the principal predictors for wage. Therefore, a (Gaussian) linear
model that predicts \code{lwage76} by \code{ed76}, \code{exp76}
(linear and squared), and \code{black} seems a suitable base model for
the examination of the racial wage gap.

\par

Since the literature \citep[e.g.,][]{Ashenfelter1999} has widely
discussed the endogeneity problem in regressing wages on schooling,
we implement an instrumental variable (IV) approach using
college proximity (\code{nearc4}) as the instrument
for schooling (\code{ed76}). This instrument, which we
computed with

%TC:ignore
<<school-IV>>=
Schooling$ed76.IV <- fitted(lm(ed76 ~ nearc4, Schooling))
@
%TC:endignore

has been proposed and evaluated by \cite{Card1993}. We rely on
their evaluation and do not go into detail, because the endogeneity
problem is not the point of this illustration.

\par

Using the instrument \code{ed76.IV} for \code{ed76}, we fit the intended
base model that includes the Mincer equation and the interesting
\code{black} dummy in the predictor function with

%TC:ignore
<<school-glm>>=
lm.School <- lm(lwage76 ~ ed76.IV + exp76 + I(exp76^2) + black,
                data = Schooling)
@
<<label = school-glm, echo=FALSE>>=
summary(lm.School)$coef[, 1:3]
@
%TC:endignore

The fit reveals that \code{black} has a significant ($t$~value $>2$)
negative impact on \code{lwage76}.

\par

The aim of this application is to illustrate how the TVCM could be
used to study moderations on the effect of \code{black}. To do this, we
consider the covariates of 3 to 11 of Table~\ref{vcrpart-tab:tab-earnings} as
potential moderators. Furthermore, we want to account for the direct
effects of the covariates 5 to 11 on wage, which are those covariates
not included in \code{lm.School}. To integrate these two extensions,
we replace the constant coefficient of \code{black} with a varying
coefficient and we replace the global intercept with a varying
intercept. However, we continue to assume the Mincer equation and,
therefore, use the same specification for the direct effects of
\code{ed76.IV} and \code{exp76} as in \code{lm.School}. To fit the
described extended model, we use the following formula.

%TC:ignore
<<label = school-formula, eval = TRUE, echo = TRUE>>=

f.School <- lwage76 ~ -1 + ed76.IV + exp76 + I(exp76^2) +
  vc(age76, momdad14, south66, south76, famed, enroll76, smsa76) +
  vc(ed76.IV, exp76, age76, momdad14, south66,
     south76, famed, enroll76, smsa76, by = black)
@
%TC:endignore

Then, we fit the varying coefficient model using

%TC:ignore
<<label = school-fitting, eval = FALSE, echo = TRUE>>=

vcm.School <- tvcglm(formula = f.School, data = Schooling,
                     family = gaussian(), control = control)
@
%TC:endignore

\begin{figure}[tb]
  \centering
  \setkeys{Gin}{width=0.4\textwidth}

<<label = school-fig-cv, fig = TRUE, echo = FALSE, width = 3.5, height = 3>>=

par(mgp = c(2, 1, 0), mar = c(3,3,0.1,0.1))
plot(vcm.School, "cv",
     xlab = expression(lambda),
     ylab = "Validation error",
     legend = FALSE)

@
\caption[\code{School} data: 5-fold cross-validated
error]{\code{vcm.School}: 5-fold cross-validated error
  in function of $\lambda$.}
\label{fig:cv-schooling}
\end{figure}

Figure~\ref{fig:cv-schooling} shows the 5-fold cross-validated error
as a function of $\lambda$. The estimated
$\hat{\lambda} = \Sexpr{round(vcm.School$info$cv$cp.hat,digits=2)}$ is
almost at the minimum of the evaluated $\lambda$ values. If we
decrease the control parameter \code{mindev} to $0.5$, then
$\hat{\lambda}$ will be situated in a clear dump at about $6$. Compared
to the tree structures below for which $\hat{\lambda} =
\Sexpr{round(vcm.School$info$cv$cp.hat,digits=2)}$ was used for
pruning, $\lambda = 6$ yields additional splits for the varying
intercept, yet the same tree structure for the varying coefficient
of \code{black}.

\begin{figure}[bt]
  \centering
  \setkeys{Gin}{width=1\textwidth}

<<label = school-fig-tree, fig = TRUE, echo = FALSE, width = 10, height = 5.5>>=

grid.newpage()
pushViewport(viewport(layout = grid.layout(1, 2, widths = c(0.72,0.28))))
pushViewport(viewport(layout.pos.col = 1))
plot(vcm.School, type = "coef", part = 1, nobs = FALSE,
     newpage = FALSE, gp = gpar(fontsize = 11))
upViewport()
pushViewport(viewport(layout.pos.col = 2))
plot(vcm.School, type = "coef", part = 2,
     newpage = FALSE)
upViewport()
upViewport()
@
\caption[\code{Schooling} data: Fitted tree
structures and nodewise coefficient plots]{\code{vcm.School}: Fitted
  tree structures and nodewise coefficient plots. Left panel: The
  varying intercept. Right panel: The varying race gap.}
\label{fig:coef-schooling}
\end{figure}

The fitted varying intercept and varying wage gap are shown in
Figure~\ref{fig:coef-schooling}. The varying intercept on the left
consists of $\Sexpr{width(vcm.School)[1]}$ terminal nodes. The tree
structure suggests that, in particular, \code{age76} and \code{smsa76}
(standard metropolitan statistical area) have strong direct effects on
wage. We do not study the varying intercept in detail because it was
mainly implemented to allow the study of the racial wage gap while
controlling for the direct effects of the considered variables.

\par

The varying racial wage gap, shown in the right panel of
Figure~\ref{fig:coef-schooling}, includes three strata. It turns out
that the gap is particularly negative for people who live in a
southern state and have high working experience. For people who live
in the north or with a low working experience (equal or less than 9 years)
in the south, the gap is smaller. However, the negative gap remains.

\par

The estimated non-varying coefficients for \code{ed76.IV} and
\code{exp76} (linear, squared) can be extracted using the \code{summary}
or the \code{coef} functions, for example, with

%TC:ignore
<<label = school-nonvarcoef>>=

coef(vcm.School)$fe
@
%TC:endignore

\subsection{The effect of parental leave duration on return to work}
\label{vcrpart-sec:PL}

As the last application, we consider an example from the literature on
the effects of welfare reforms. Specifically, we investigate the
effect of the 1990 reform of the Austrian parental-leave (PL)
system. Before 1990, working women had the right to stay off work
after childbirth up to 12 months and, thereafter, return to the same
(or similar) job at the same employer. The 1990 reform extended the
duration of this leave from 12 months to 24 months. \cite{Lalive2009}
investigated the effect of the 1990 PL reform on various fertility and
labor market outcomes, based on linear regression models and using the
Austrian Social Security Database (ASSD). They provide a background to
the Austrian PL system and describe the data subset.\footnote{The data
  subset is available from
  \url{https://sites.google.com/site/rafaellalive/research}.} Here,
using the same data, we reanalyze the effect of the reform on whether
women returned to work at least once in the 10 years after childbirth.

\par

The subset of the ASSD data includes
$\Sexpr{format(nrow(PL),big.mark=",")}$ women who gave birth in June
or July 1990 and were eligible to access the Austrian PL system. With
\pkg{vcrpart}, the data are loaded by

%TC:ignore
<<label = pl-data>>=

data("PL")
@
%TC:endignore

The interesting PL reform dummy is \code{july}. A `$0$' in
\code{july} means childbirth in June 1990, which is the last month
under the old PL system,  and a `$1$' indicates a birth in July
1990, which is the first month under the new PL system. The response
variable \code{uncj10} is binary, where `$1$' refers to women who
returned to work at least once in the 10 years after the considered
childbirth. Both \code{july} and  \code{uncj10}  are summarized in
Table~\ref{vcrpart-tab:tab-PL}, along with eight further covariates used as
moderators.%% \footnote{Descriptive statistics of these
  %% variables can be found in the
  %% Tables~\ref{vcrpart-appendix-tab:pl-nominal} and
  %% \ref{vcrpart-appendix-tab:pl-continuous}.}

\begin{table}[htbp]
  \centering
  \small
  \begin{tabular}{rp{4.75cm}lll}
    \hline
    & Variable & Label & Scale & Range \\
    \hline
    1  & Whether returned to work 0-120 months after
    childbirth & \code{uncj10} & Binary & 0 = No, 1 = Yes \\
    2 & Whether childbirth was in July
    & \code{july} & Binary & 0 = June, 1 = July \\
    3  & Years employed before birth & \code{workExp} & Continuous &
    [0, 17.5] \\
    4 & Years unemployed before birth & \code{unEmpl} & Continuous &
    [0, 5.8] \\
    5 & Daily earnings at birth & \code{laborEarnings} & Cont. (\euro/d) &
    $[0, 1510.7]$ \\
    6 & Whether white collar worker & \code{whiteCollar} & Binary &
    no, yes \\
    7 & Daily earnings 1989 & \code{wage} & Cont. (\euro/d) & $[0, 98.6]$
    \\
    8 &  Age & \code{age} & Ordinal & 1, $[ 15{-}19 ]$; \ldots; 5,
    $[35{-}44]$ \\
    9 & Industry & \code{industry.SL} & Nominal & 20 categories \\
    10 & Region & \code{region.SL} &  Nominal & 9 categories \\
    \hline
  \end{tabular}
  \normalsize
  \caption[\code{PL} data: Variables]{The subset of used variables of
    the \code{PL} data.}
  \label{vcrpart-tab:tab-PL}
\end{table}

First, we consider a simple logistic model for
\code{uncj10} with only \code{july} in the predictor function.

%TC:ignore
<<label = pl-glm>>=

glm.PL <- glm(uncj10 ~ july, data = PL, family = binomial)
@
%TC:endignore

%TC:ignore
<<label = app-glm-coef, echo = FALSE>>=
summary(glm.PL)$coefficients[, 1:3]
@
%TC:endignore

The estimated effect of \code{july} is
$\Sexpr{round(coef(glm.PL)["july"], 2)}$ (corresponding to an odds ratio
of $e^{\Sexpr{round(coef(glm.PL)["july"], 2)}} =
\Sexpr{round(exp(coef(glm.PL)["july"]), 2)}$) and is significant
(\textbar$z$~value\textbar $>2$). This means that the 1990 PL reform
decreases the logit for returning to work.

\par

The aim of this application is to investigate whether and how the
effect of the PL reform is moderated by covariates 3 to 10 of
Table~\ref{vcrpart-tab:tab-PL}, which include for example age and
region. Furthermore, we want to study such moderation by considering
the direct effects of the moderators. To implement this, we
use the additive expansion for multivariate varying coefficients
introduced in Section~\ref{vcrpart-sec:contrasts}. The additive
expansion is restrictive because it ignores interactions between
moderators. However, in applied regression analysis it is common to
limit the scope on first-order interactions between the predictor of
interest and further covariates \citep[e.g.,][]{Cox1984}. For each
considered moderator, the intended model adds varying intercepts and
varying coefficients for \code{july} to the simple model \code{glm.PL},
and is specified by the formula

%TC:ignore
<<label = pl-formula, eval = TRUE>>=

f.PL <- uncj10  ~  1 + july + vc(age) + vc(age, by = july) +
    vc(workExp) + vc(workExp, by = july) +
    vc(unEmpl) + vc(unEmpl, by = july) +
    vc(laborEarnings) + vc(laborEarnings, by = july) +
    vc(whiteCollar) + vc(whiteCollar, by = july) +
    vc(wage) + vc(wage, by = july) +
    vc(industry.SL) + vc(industry.SL, by = july) +
    vc(region.SL) + vc(region.SL, by = july)
@
%TC:endignore

Note that we keep the global intercept and the global effect of
\code{july} as global references for the individual varying
coefficients. The model is fitted with

%TC:ignore
<<label = pl-fitting, eval = FALSE>>=

vcm.PL <- tvcglm(formula = f.PL, family = binomial(),
                    data = PL, control = control)
@
%TC:endignore

\begin{figure}[htbp]
  \centering
  \setkeys{Gin}{width=0.4\textwidth}

<<label = pl-fig-cv, fig = TRUE, echo = FALSE, width = 3.5, height = 3>>=

par(mgp = c(2, 1, 0), mar = c(3,3,0.1,0.1))
plot(vcm.PL, "cv",
     xlab = expression(lambda),
     ylab = "Validation error",
     legend = FALSE)
@
\caption[\code{PL} data: 5-fold cross-validated error]{\code{vcm.PL}:
  5-fold cross-validated error in function of $\lambda$.}
\label{fig:cv-PL}
\end{figure}

Figure~\ref{fig:cv-PL} shows that the 5-fold cross-validated error is
smallest at $\hat{\lambda} =
\Sexpr{round(vcm.PL$info$cv$cp.hat,2)}$. The error curve is relatively
flat on the right of the minimum.

\begin{figure}[ht]
  \centering
  \setkeys{Gin}{width=1\textwidth}

<<label = pl-fig-tree, fig = TRUE, echo = FALSE, width = 12, height = 9>>=

fac <- 0.9
subs <- which(width(vcm.PL) > 1)
ylim1 <- c(-1, 0.8)
ylim2 <- c(-1.4, 0.5)
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow = 2, ncol = 3,
                        widths = c(1/3, 1/3, 1/3))))
pushViewport(viewport(layout.pos.col = 1, layout.pos.row = 1))
plot(vcm.PL, type = "coef", part = subs[1], plot_gp = list(ylim = ylim1),
     newpage = FALSE)
upViewport()
pushViewport(viewport(layout.pos.col = 1, layout.pos.row = 2))
plot(vcm.PL, type = "coef", part = subs[2], plot_gp = list(ylim = ylim2),
     newpage = FALSE)
upViewport()
pushViewport(viewport(layout.pos.col = 2, layout.pos.row = 1))
plot(vcm.PL, type = "coef", part = subs[3], plot_gp = list(ylim = ylim1),
     newpage = FALSE)
upViewport()
pushViewport(viewport(layout.pos.col = 3, layout.pos.row = 1))
plot(vcm.PL, type = "coef", part = subs[4], plot_gp = list(ylim = ylim1),
     newpage = FALSE)
upViewport()
pushViewport(viewport(layout.pos.col = 2, layout.pos.row = 2))
plot(vcm.PL, type = "coef", part = subs[5], plot_gp = list(ylim = ylim2),
     newpage = FALSE)
upViewport()
upViewport()
@
\caption[\code{PL} data: Fitted tree structures and nodewise
coefficient plots]{\code{vcm.PL}: Fitted varying coefficients with at
  least one split. Top row: The varying intercepts. Bottom row: The
  varying PL reform effects. The coefficients are
  contributions to the global intercept $\hat{\beta}^{\texttt{(Intercept)}} =
  \Sexpr{round(coef(vcm.PL)$fe["(Intercept)"], 2)}$ resp. the global
  PL reform effect $\hat{\beta}^{\texttt{july}} =
  \Sexpr{round(coef(vcm.PL)$fe["july"], 2)}$.}
\label{fig:PL}
\end{figure}

Figure~\ref{fig:PL} renders the fitted varying coefficients with at
least one split. The top row shows the varying intercepts, which
are contributions to the global intercept $\hat{\beta}^{\texttt{(Intercept)}} =
\Sexpr{round(coef(vcm.PL)$fe["(Intercept)"], 2)}$, and are interpreted
as direct effects on the logits for return to work. The result
suggests that women with low working experience ($\le2.2$ years) and
a high wage ($>45.8$\euro/d)  have increased logits to return to work,
and that there are also differences  between industries. Specifically, working
in an industry corresponding to Node~3, which includes service
industries such as social insurance, education and bank industries,
has a positive direct effect on return to work.

\par

<<label = pl-coef, echo = FALSE>>=

## extract coefficients for text
effGL <- coef(vcm.PL)$fe[2]
effWED1 <- coef(vcm.PL)$vc$C[1]
effWED2 <- coef(vcm.PL)$vc$C[2]
effWEM1 <- coef(vcm.PL)$vc$D[1]
effREM1 <- coef(vcm.PL)$vc$P[1]
effREM3 <- coef(vcm.PL)$vc$P[3]
@

The global effect of the PL reform on the logits for return to work is
estimated to be $\hat{\beta}^{\texttt{july}} =
\Sexpr{round(coef(vcm.PL)$fe["july"], 2)}$. The moderation effects of
the two selected variables, working experience and region, are shown
in the bottom row of Figure~\ref{fig:PL}. From the nodewise
coefficient plots, we learn that low working experience ($\le5.3$ years)
increases $\hat{\beta}^{\texttt{july}}$ by \Sexpr{round(effWEM1,2)},
and living in Vienna (W) or Lower Austria (NOe) increases
$\hat{\beta}^{\texttt{july}}$ by \Sexpr{round(effREM3,2)}. These
positive contributions imply that the effect of the PL reform locally
surpasses zero, especially for those women who combine the
two characteristics low working experience and living
  in Vienna or Lower Austria.

\section{Discussion and outlook}
\label{vcrpart-sec:conclusion}

In this study, we showed how to use the TVCM algorithm for varying
coefficient regression, as well as its implementation in the
\proglang{R} package \pkg{vcrpart}. Unlike alternative tree-based
algorithms, the TVCM can build a separate partition for each varying
coefficient. Thus, it allows us to select moderators individually for each
varying coefficient and to specify coefficient-specific sets of
moderators. Furthermore, Section~\ref{vcrpart-sec:evaluation} provides empirical
evidence showing that TVCM builds slightly more accurate
and/or more parsimonious models than competing tree-based algorithms. It also
assesses the ability of TVCM to identify an underlying
data model. In addition to the description of the TVCM, we discussed
the model specification, provided \proglang{R} commands and
demonstrated the scope of TVCM by applying the algorithm to
different data sets.

\par

\label{vcrpart-sec:conclusion-spurious}
It is worth mentioning here that TVCM could in some situations wrongly
identify a moderator effect in place of a main effect of the
variable.\footnote{Thanks to the reviewer who pointed that out.}
Such spurious moderator effects could appear when the moderator has in
truth a main effect on the response while the variable is not
specified as a predictor, nor as a moderator of the intercept. Such
potential moderators may, when one of the specified predictors remains
almost constant, reflect their own main effect on the response through
their interaction with that predictor. Therefore, it would be good
practice to test, before drawing any definite conclusion, that every
identified moderator effect does not change significantly when the
moderator is also entered as a predictor.

\par

\label{vcrpart-sec:conclusion-theoreticalproperties}
Further research should investigate the theoretical properties of the
TVCM in more detail. This could include simulation studies and/or
comparisons with smoothing splines and/or kernel regression
techniques, in line with the comparison study of \cite{Wang2013}.
The simulation study described in
Section~\ref{vcrpart-sec:simulation-study} is a first attempt in that
direction. It suggests that the performance of TVCM for identifying an
underlying data model improves with increasing numbers of
observations, and that TVCM is more powerful than the single-partition
approach in the case where the coefficient functions differ from each
others.

\par

There also is potential for improving the TVCM. This could include: (i)
Developing an unbiased selection procedure for partitioning; (ii)
decreasing the computational time; (iii) refining the pruning
criterion; and (iv) stabilizing the algorithm.

\par

Improvement (i) requires finding an alternative criterion that does
not tend to select partitions, nodes, and moderators with many split
candidates (cf., Sec.~\ref{vcrpart-sec:partitioning}). At the outset,
we considered implementing the score-based coefficient constancy tests
of \cite{Zeileis2007}, used in the MOB algorithm. We were particularly
interested into these tests because they would have allowed to select
the partition, the node and the moderator based on the scores of the
current model $\widehat{\mathcal{M}}$ (\ref{vcrpart-eq:alg}),
without estimating search models. However, we discarded the idea
because the tests work under the condition that the predictors of the
model are stationary and ergodic \citep[cf.,][]{Andrews1993} with
respect to the tested moderator, which seems difficult to control when
partitioning coefficient-wise. Another adjustment would be to derive
the distribution of the maximally selected likelihood ratio statistics
$D_{k'm'l'j'}$ of Algorithm~\ref{vcrpart-alg:partitioning}. This would allow
us to select the split based on $p$-values, which eliminates the
dependence of the selection on the number of splits in the moderator
variable. \cite{Andrews1993} developes the distribution of maximally
selected likelihood ratio statistics, however, again under the
stationarity assumption. Indeed, the stationarity assumption could be
resolved by using bootstrap techniques \citep[e.g.,][]{Jouini2008}, but
such techniques are computationally complex. Finally, $F$- or
$\chi^2$-type tests, such as those proposed in \cite{Loh1997}, could
be implemented. For example, \cite{Brandmaier2012} implement such
tests for building structural equation model trees, and they show that
their implementation reduces the variable selection bias substantially.

\par

With regard to point (ii), the TVCM seems more time consuming than the
alternative algorithms (cf., Sec.~\ref{vcrpart-sec:pima}), although we
integrated several acceleration techniques and parallelized the
cross-validation.  This hindrance, which might be relevant for big data
applications, could be partly solved by rewriting the bottleneck functions
in a low-level programming language. With regard to improvement (iii),
we could consider refining the cost-complexity criterion
of Equation~\ref{vcrpart-eq:pe}, which assumes that the `optimism' of the training
error linearly increases with each split. \cite{Ye1998} showed that
this assumption is violated for CART, and the same probably applies to
the TVCM. \cite{Ye1998} and \cite{Efron2004} provide more accurate
solutions using resampling techniques, though these solutions are
highly time consuming. Finally, with regard to improvement (iv), to
stabilize the algorithm regarding perturbations to the data and to
improve the accuracy, we provide with the \code{fvcglm} function an
implementation of the random forest ensemble
algorithm \citep{Breiman2001} for the TVCM. We have not addressed this
implementation here so as to focus on the original parts of our work.


\par

Along with \code{tvcglm},  \code{tvcglm\_control}, \code{splitpath},
\code{prunepath}, and \code{plot}, this study introduced the main
functions for the fitting and diagnosis of coefficient-wise tree-based
varying coefficient models. Additional functions provided by \pkg{vcrpart},
such as \code{summary} and \code{predict}, are described in the reference manual.

\section*{Acknowledgments}

This publication results from research work carried out within the
framework of the Swiss National Center of Competence in Research
LIVES, which is financed by the Swiss National Science Foundation. The
authors are grateful to the Swiss National Science Foundation for its
financial support.

<<label = applicatons-save, eval = FALSE, echo = FALSE>>=

## save all fitted models, those being commented out by default
if (run | !"vcrpart-applications.RData" %in% dir("RData/")) {
  save(UCBA, cv.UCBA, vcm.UCBA,
     Pima, vcm.Pima.1, vcm.Pima.2, mob.Pima,
     Schooling, vcm.School,
     PL, vcm.PL,
     file = "RData/vcrpart-applications.RData")
}
@

%%\bibliography{vcrpart}

\begin{thebibliography}{48}
\newcommand{\enquote}[1]{``#1''}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi:\discretionary{}{}{}#1}\else
  \providecommand{\doi}{doi:\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi
\providecommand{\eprint}[2][]{\url{#2}}

\bibitem[{Alexander and Grimshaw(1996)}]{Alexander1996}
Alexander WP, Grimshaw SD (1996).
\newblock \enquote{Treed Regression.}
\newblock \emph{Journal of Computational and Graphical Statistics},
  \textbf{5}(2), 156--175.

\bibitem[{Andrews(1993)}]{Andrews1993}
Andrews DWK (1993).
\newblock \enquote{Tests for Parameter Instability and Structural Change with
  Unknown Change Point.}
\newblock \emph{Econometrica}, \textbf{61}(4), 821--56.

\bibitem[{Arulampalam \emph{et~al.}(2007)Arulampalam, Booth, and
  Bryan}]{Arulampalam2007}
Arulampalam W, Booth AL, Bryan ML (2007).
\newblock \enquote{Is There A Glass Ceiling Over Europe? Exploring the Gender
  Pay Gap Across the Wage Distribution.}
\newblock \emph{Industrial and Labor Relations Review}, \textbf{60}(2),
  163--186.

\bibitem[{Ashenfelter and Card(1999)}]{Ashenfelter1999}
Ashenfelter O, Card D (eds.) (1999).
\newblock \emph{Handbook of Labor Economics}, volume~3.
\newblock Elsevier, Amsterdam, Netherlands.

\bibitem[{Bache and Lichman(2013)}]{Bache2013}
Bache K, Lichman M (2013).
\newblock \enquote{{UCI} Machine Learning Repository.}
\newblock \urlprefix\url{http://archive.ics.uci.edu/ml}.

\bibitem[{Bickel \emph{et~al.}(1975)Bickel, Hammel, and
  O'Connell}]{Bickel1975a}
Bickel PJ, Hammel EA, O'Connell JW (1975).
\newblock \enquote{Sex Bias in Graduate Admissions: Data from {B}erkeley.}
\newblock \emph{Science}, \textbf{187}(4175), 398--403.

\bibitem[{Brandmaier \emph{et~al.}(2012)Brandmaier, von Oertzen, McArdle, and
  Lindenberger}]{Brandmaier2012}
Brandmaier AM, von Oertzen T, McArdle JJ, Lindenberger U (2012).
\newblock \enquote{Structural Equation Model Trees.}
\newblock \emph{Psychological Methods}, \textbf{18}(1), 71--86.

\bibitem[{Breiman(2001)}]{Breiman2001}
Breiman L (2001).
\newblock \enquote{Random Forests.}
\newblock \emph{Machine Learning}, \textbf{45}(1), 5–32.

\bibitem[{Breiman \emph{et~al.}(1984)Breiman, Friedman, Olshen, and
  Stone}]{Breiman1984}
Breiman L, Friedman JH, Olshen RA, Stone CJ (1984).
\newblock \emph{{C}lassification and Regression Trees}.
\newblock Wadsworth, New York, USA.

\bibitem[{B\"urgin(2016)}]{Burgin2014}
B\"urgin R (2016).
\newblock \emph{\pkg{vcrpart}: {T}ree-Based Varying Coefficient Regression for
  Generalized Linear and Ordinal Mixed Models}.
\newblock \proglang{R}-package version-0.4-1,
  \urlprefix\url{http://cran.r-project.org/web/packages/vcrpart/}.

\bibitem[{B\"urgin and Ritschard(2015)}]{BuerginRitschard2015CSDA}
B\"urgin R, Ritschard G (2015).
\newblock \enquote{Tree-Based Varying Coefficient Regression for Longitudinal
  Ordinal Responses.}
\newblock \emph{Computational Statistics \& Data Analysis}, \textbf{86},
  65--80.
\newblock \doi{10.1016/j.csda.2015.01.003}.

\bibitem[{Card(1993)}]{Card1993}
Card D (1993).
\newblock \enquote{Using Geographic Variation in College Proximity to Estimate
  the Return to Schooling.}
\newblock \emph{Technical report}, National Bureau of Economic Research.

\bibitem[{Chambers and Hastie(1992)}]{Chambers1991}
Chambers JM, Hastie T (1992).
\newblock \emph{Statistical Models in {S}}.
\newblock Advanced Books \& Software. Wadsworth \& Brooks/Cole, Pacific Grove,
  USA.

\bibitem[{Cox(1984)}]{Cox1984}
Cox DR (1984).
\newblock \enquote{Interaction.}
\newblock \emph{International Statistical Review / Revue Internationale de
  Statistique}, \textbf{52}(1), 1--24.

\bibitem[{Croissant(2015)}]{Croissant2014}
Croissant Y (2015).
\newblock \emph{\pkg{{E}cdat}: {D}ata Sets for Econometrics}.
\newblock \proglang{R}-package version-0.2-9,
  \urlprefix\url{http://CRAN.R-project.org/package=Ecdat}.

\bibitem[{Efron(2004)}]{Efron2004}
Efron B (2004).
\newblock \enquote{The Estimation of Prediction Error; Covariance Penalties and
  Cross-Validation.}
\newblock \emph{Journal of the American Statistical Association},
  \textbf{99}(467), 619--642.

\bibitem[{Fahrmeir and Tutz(2001)}]{Fahrmeir2001}
Fahrmeir L, Tutz G (2001).
\newblock \emph{Multivariate Statistical Modelling Based on Generalized Linear
  Models}.
\newblock Springer Series in Statistics, 2 edition. Springer-Verlag, New York,
  USA.

\bibitem[{Fan and Zhang(2008)}]{Fan2008}
Fan J, Zhang W (2008).
\newblock \enquote{Statistical Methods with Varying Coefficient Models.}
\newblock \emph{Statistics and Its Interface}, \textbf{1}(1), 179--195.

\bibitem[{Hastie and Tibshirani(1993)}]{Hastie1993}
Hastie T, Tibshirani R (1993).
\newblock \enquote{Varying-Coefficient Models.}
\newblock \emph{Journal of the Royal Statistical Society B}, \textbf{55}(4),
  757--796.

\bibitem[{Hayes(2013)}]{Hayes2013}
Hayes AF (2013).
\newblock \emph{Introduction to Mediation, Moderation, and Conditional Process
  Analysis: {A} Regression-Based Approach}.
\newblock Guilford Press, New York, USA.

\bibitem[{Hayfield and Racine(2008)}]{Hayfield2008}
Hayfield T, Racine JS (2008).
\newblock \enquote{Nonparametric Econometrics: The np Package.}
\newblock \emph{Journal of Statistical Software}, \textbf{27}(5), 1--32.

\bibitem[{Heim(2007)}]{Heim2007}
Heim S (2007).
\newblock \enquote{{svcm}: 2{D} and 3{D} Space-Varying Coefficient Models in
  {R}.}
\newblock \emph{R package reference manual}, CRAN.
\newblock 0.1.2, \urlprefix\url{http://cran.r-project.org/package=svcm}.

\bibitem[{Hornik \emph{et~al.}(2009)Hornik, Buchta, and Zeileis}]{Hornik2009}
Hornik K, Buchta C, Zeileis A (2009).
\newblock \enquote{Open-Source Machine Learning: {R} Meets {Weka}.}
\newblock \emph{Computational Statistics}, \textbf{24}(2), 225--232.

\bibitem[{Hothorn \emph{et~al.}(2016)Hothorn, B\"uhlmann, Kneib, Schmid, and
  Hofner}]{Hothorn2014a}
Hothorn T, B\"uhlmann P, Kneib T, Schmid M, Hofner B (2016).
\newblock \emph{\pkg{mboost}: {M}odel-Based Boosting}.
\newblock \proglang{R}-package version-2.6-0,
  \urlprefix\url{http://CRAN.R-project.org/package=mboost}.

\bibitem[{Hothorn \emph{et~al.}(2006)Hothorn, Hornik, and
  Zeileis}]{Hothorn2006}
Hothorn T, Hornik K, Zeileis A (2006).
\newblock \enquote{Unbiased Recursive Partitioning: A Conditional Inference
  Framework.}
\newblock \emph{Journal of Computational and Graphical Statistics},
  \textbf{15}(3), 651--674.

\bibitem[{Hothorn and Zeileis(2014)}]{Hothorn2014}
Hothorn T, Zeileis A (2014).
\newblock \enquote{{partykit}: {A} Modular Toolkit for Recursive Partytioning
  in {R}.}
\newblock In \emph{Working Papers in Economics and Statistics, Research
  Platform Empirical and Experimental Economics}, 2014-10. Universit\"at
  Innsbruck.

\bibitem[{Jouini(2008)}]{Jouini2008}
Jouini J (2008).
\newblock \enquote{Bootstrap Methods for Single Structural Change Tests: Power
  versus Corrected Size and Empirical Illustration.}
\newblock \emph{Statistical Papers}, \textbf{51}(1), 85--109.

\bibitem[{Lalive and Zweim\"{u}ller(2009)}]{Lalive2009}
Lalive R, Zweim\"{u}ller J (2009).
\newblock \enquote{Does Parental Leave Affect Fertility and Return-to-Work?
  Evidence from Two Natural Experiments.}
\newblock \emph{The Quarterly Journal of Economics}, \textbf{124}(3),
  1363--1402.

\bibitem[{Landwehr \emph{et~al.}(2005)Landwehr, Hall, and Frank}]{Landwehr2005}
Landwehr N, Hall M, Frank E (2005).
\newblock \enquote{Logistic Model Trees.}
\newblock \emph{Machine Learning}, \textbf{95}(1-2), 161--205.

\bibitem[{Leisch and Dimitriadou(2010)}]{Leisch2010}
Leisch F, Dimitriadou E (2010).
\newblock \emph{\pkg{mlbench}: Machine Learning Benchmark Problems}.
\newblock \proglang{R}-package version-2.1-1,
  \urlprefix\url{http://CRAN.R-project.org/package=mlbench}.

\bibitem[{Loh(2002)}]{Loh2002}
Loh WY (2002).
\newblock \enquote{Regression Trees with Unbiased Variable Selection and
  Interaction Detection.}
\newblock \emph{Statistica Sinica}, \textbf{12}(2), 361--386.

\bibitem[{Loh and Shih(1997)}]{Loh1997}
Loh WY, Shih YS (1997).
\newblock \enquote{Split Selection Methods for Classification Trees.}
\newblock \emph{Statistica Sinica}, \textbf{7}, 815--840.

\bibitem[{McCullagh and Nelder(1989)}]{McCullagh1983}
McCullagh P, Nelder J (1989).
\newblock \emph{Generalized Linear Models}.
\newblock Monographs on Statistics and Applied Probability, 2nd edition.
  Chapman and Hall, London, UK.

\bibitem[{Mincer(1974)}]{Mincer1974}
Mincer JA (1974).
\newblock \emph{Schooling, Experience, and Earnings}.
\newblock NBER Books. National Bureau of Economic Research, Inc.

\bibitem[{Quinlan(1992)}]{Quinlan1992}
Quinlan JR (1992).
\newblock \enquote{Learning with Continuous Classes.}
\newblock In \emph{Proceedings of the 5th Australian Joint Conference on
  Artificial Intelligence}, pp. 343--348. World Scientific, Singapore.

\bibitem[{Quinlan(1993)}]{Quinlan1993}
Quinlan JR (1993).
\newblock \emph{{C}4.5: {P}rograms for Machine Learning}.
\newblock Morgan Kaufmann Publishers Inc., San Francisco, USA.

\bibitem[{{\proglang{R} Core Team}(2016)}]{RCoreTeam2014}
{\proglang{R} Core Team} (2016).
\newblock \emph{\proglang{R}: A Language and Environment for Statistical
  Computing, Version 3.3.1}.
\newblock R Foundation for Statistical Computing, Vienna, Austria.
\newblock \urlprefix\url{http://www.R-project.org}.

\bibitem[{Russell and Norvig(2003)}]{Russell2003}
Russell SJ, Norvig P (2003).
\newblock \emph{Artificial Intelligence: {A} Modern Approach}.
\newblock 3 edition. Pearson Education Inc., New Jersey, USA.

\bibitem[{Smith \emph{et~al.}(1988)Smith, Everhart, Dickson, Knowler, and
  Johannes}]{Smith1988}
Smith J, Everhart J, Dickson W, Knowler W, Johannes R (1988).
\newblock \enquote{Using the {ADAP} Learning Algorithm to Forecast the Onset of
  Diabetes Mellitus.}
\newblock In \emph{Proceedings of the Annual Symposium on Computer Application
  in Medical Care}, pp. 261--265. American Medical Informatics Association.

\bibitem[{Therneau \emph{et~al.}(2015)Therneau, Atkinson, and
  Ripley}]{Therneau2014}
Therneau T, Atkinson B, Ripley BD (2015).
\newblock \emph{\pkg{rpart}: {R}ecursive Partitioning and Regression Trees}.
\newblock \proglang{R}-package version-4.1-10,
  \urlprefix\url{http://CRAN.R-project.org/package=rpart}.

\bibitem[{Venables and Ripley(2002)}]{Venables2002}
Venables WN, Ripley BD (2002).
\newblock \emph{Modern Applied Statistics with {S}}.
\newblock Statistics and Computing, 4 edition. Springer-Verlag, New York.

\bibitem[{Wang and Hastie(2014)}]{Wang2013}
Wang JC, Hastie T (2014).
\newblock \enquote{Boosted Varying-Coefficient Regression Models for Product
  Demand Prediction.}
\newblock \emph{Journal of Computational and Graphical Statistics},
  \textbf{23}(2), 361--382.

\bibitem[{Wood(2006)}]{Wood2006}
Wood S (2006).
\newblock \emph{Generalized Additive Models: {A}n Introduction with {R}}.
\newblock Texts in Statistical Science. Chapman and Hall, Boca Raton, USA.

\bibitem[{Ye(1998)}]{Ye1998}
Ye J (1998).
\newblock \enquote{On Measuring and Correcting the Effects of Data Mining and
  Model Selection.}
\newblock \emph{Journal of the American Statistical Association},
  \textbf{93}(441), 120--313.

\bibitem[{Yusuf \emph{et~al.}(1991)Yusuf, Wittes, Probstfield, and
  Tyroler}]{Yusuf1991}
Yusuf S, Wittes J, Probstfield J, Tyroler HA (1991).
\newblock \enquote{Analysis and Interpretation of Treatment Effects in
  Subgroups of Patients in Randomized Clinical Trials.}
\newblock \emph{Journal of the American Medical Association}, \textbf{266}(1),
  93--98.

\bibitem[{Zeileis and Hornik(2007)}]{Zeileis2007}
Zeileis A, Hornik K (2007).
\newblock \enquote{Generalized {M}-Fluctuation Tests for Parameter
  Instability.}
\newblock \emph{Statistica Neerlandica}, \textbf{61}(4), 488--508.

\bibitem[{Zeileis \emph{et~al.}(2006)Zeileis, Hothorn, and
  Hornik}]{Zeileis2006}
Zeileis A, Hothorn T, Hornik K (2006).
\newblock \enquote{Evaluating Model-Based Trees in Practice.}
\newblock In \emph{Research Report Series}, 32. Wirtschaftsuniversit\"at Wien.
\newblock \urlprefix\url{http://epub.wu.ac.at/1484/1/document.pdf}.

\bibitem[{Zeileis \emph{et~al.}(2008)Zeileis, Hothorn, and
  Hornik}]{Zeileis2005}
Zeileis A, Hothorn T, Hornik K (2008).
\newblock \enquote{Model-Based Recursive Partitioning.}
\newblock \emph{Journal of Computational and Graphical Statistics},
  \textbf{17}(2), 492--514.

\end{thebibliography}

\end{document}
